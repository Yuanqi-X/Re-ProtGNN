{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "399364ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuanqi/Desktop/pycharm_projects/yuanqi_xue/protgnn_env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory set to: /home/yuanqi/Desktop/pycharm_projects/yuanqi_xue\n",
      "'src' added to sys.path: /home/yuanqi/Desktop/pycharm_projects/yuanqi_xue/src\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import argparse\n",
    "\n",
    "# Manually specify the project root\n",
    "project_root = \"/home/yuanqi/Desktop/pycharm_projects/yuanqi_xue\"\n",
    "\n",
    "# Change working directory to project root\n",
    "os.chdir(project_root)\n",
    "\n",
    "# Add src/ to sys.path\n",
    "src_path = os.path.join(project_root, \"src\")\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "print(f\"Working directory set to: {os.getcwd()}\")\n",
    "print(f\"'src' added to sys.path: {src_path}\")\n",
    "\n",
    "from utils.Configures import data_args, train_args, model_args, mcts_args\n",
    "from data_processing.dataUtils import load_dataset\n",
    "from models import setup_model\n",
    "from models.train import train\n",
    "from evaluation.test import test\n",
    "from evaluation.explanation import exp_visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d61856c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Main Experiment Pipeline ==========\n",
    "def main(args):\n",
    "    # Step 1: Load dataset and construct dataloaders\n",
    "    print('====================Loading Data====================')\n",
    "    dataset, input_dim, output_dim, dataloader = load_dataset()\n",
    "    print(f\"Dataset Name: {data_args.dataset_name}\")\n",
    "    print(f\"Dataset Length: {len(dataset)}\")\n",
    "\n",
    "    # Step 2: Initialize model and loss function\n",
    "    print('====================Setting Up Model====================')\n",
    "    gnnNets, criterion = setup_model(input_dim, output_dim, model_args)\n",
    "    print(f\"gnnNets: {gnnNets}\")\n",
    "\n",
    "    # Step 3: Train the model with prototype alignment and joint optimization\n",
    "    print('====================Training Model==================')\n",
    "    ckpt_dir = f\"./src/checkpoint/{data_args.dataset_name}/\"\n",
    "    train(args.clst, args.sep, dataset, dataloader, gnnNets, output_dim, criterion, ckpt_dir)\n",
    "\n",
    "    # Step 4: Evaluate the best model on the test set\n",
    "    print('====================Testing==================')\n",
    "    best_checkpoint = torch.load(os.path.join(ckpt_dir, f'{model_args.model_name}_best.pth'))\n",
    "    gnnNets.update_state_dict(best_checkpoint['net'])\n",
    "    test(dataloader['test'], gnnNets, criterion)\n",
    "\n",
    "    # Step 5: Output explanations for selected graphs\n",
    "    print('====================Generating Explanations====================')\n",
    "    exp_visualize(dataset, dataloader, gnnNets, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81de6067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================Loading Data====================\n",
      "dataloader used\n",
      "Dataset Name: MUTAG\n",
      "Dataset Length: 188\n",
      "====================Setting Up Model====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuanqi/Desktop/pycharm_projects/yuanqi_xue/protgnn_env/lib/python3.8/site-packages/torch_geometric/deprecation.py:13: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gnnNets: _GnnNets(\n",
      "  (model): GINNet(\n",
      "    (gnn_layers): ModuleList(\n",
      "      (0): GINConv(nn=Sequential(\n",
      "        (0): Linear(in_features=7, out_features=128, bias=False)\n",
      "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Linear(in_features=128, out_features=128, bias=False)\n",
      "        (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      ))\n",
      "      (1): GINConv(nn=Sequential(\n",
      "        (0): Linear(in_features=128, out_features=128, bias=False)\n",
      "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Linear(in_features=128, out_features=128, bias=False)\n",
      "        (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      ))\n",
      "      (2): GINConv(nn=Sequential(\n",
      "        (0): Linear(in_features=128, out_features=128, bias=False)\n",
      "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Linear(in_features=128, out_features=128, bias=False)\n",
      "        (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      ))\n",
      "    )\n",
      "    (gnn_non_linear): ReLU()\n",
      "    (mlps): ModuleList(\n",
      "      (0): Linear(in_features=128, out_features=2, bias=True)\n",
      "    )\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "    (Softmax): Softmax(dim=-1)\n",
      "    (mlp_non_linear): ELU(alpha=1.0)\n",
      "    (last_layer): Linear(in_features=10, out_features=2, bias=False)\n",
      "  )\n",
      ")\n",
      "====================Training Model==================\n",
      "Graphs: 188, Avg Nodes: 17.93, Avg Edges: 19.79\n",
      "Train Epoch: 0 | Loss: 0.687 | Acc: 0.693\n",
      "saving....\n",
      "Train Epoch: 1 | Loss: 0.645 | Acc: 0.767\n",
      "saving....\n",
      "Train Epoch: 2 | Loss: 0.616 | Acc: 0.673\n",
      "Train Epoch: 3 | Loss: 0.605 | Acc: 0.767\n",
      "Train Epoch: 4 | Loss: 0.523 | Acc: 0.767\n",
      "saving....\n",
      "Train Epoch: 5 | Loss: 0.546 | Acc: 0.773\n",
      "Train Epoch: 6 | Loss: 0.513 | Acc: 0.793\n",
      "Train Epoch: 7 | Loss: 0.497 | Acc: 0.740\n",
      "saving....\n",
      "Train Epoch: 8 | Loss: 0.470 | Acc: 0.767\n",
      "Train Epoch: 9 | Loss: 0.445 | Acc: 0.780\n",
      "Train Epoch: 10 | Loss: 0.426 | Acc: 0.767\n",
      "saving....\n",
      "Train Epoch: 11 | Loss: 0.417 | Acc: 0.827\n",
      "Train Epoch: 12 | Loss: 0.425 | Acc: 0.807\n",
      "Train Epoch: 13 | Loss: 0.498 | Acc: 0.807\n",
      "Train Epoch: 14 | Loss: 0.557 | Acc: 0.753\n",
      "Train Epoch: 15 | Loss: 0.512 | Acc: 0.700\n",
      "Train Epoch: 16 | Loss: 0.554 | Acc: 0.653\n",
      "Train Epoch: 17 | Loss: 0.478 | Acc: 0.667\n",
      "Train Epoch: 18 | Loss: 0.520 | Acc: 0.673\n",
      "Train Epoch: 19 | Loss: 0.500 | Acc: 0.667\n",
      "Train Epoch: 20 | Loss: 0.425 | Acc: 0.667\n",
      "saving....\n",
      "Train Epoch: 21 | Loss: 0.485 | Acc: 0.667\n",
      "Train Epoch: 22 | Loss: 0.449 | Acc: 0.667\n",
      "Train Epoch: 23 | Loss: 0.420 | Acc: 0.667\n",
      "Train Epoch: 24 | Loss: 0.452 | Acc: 0.667\n",
      "Train Epoch: 25 | Loss: 0.454 | Acc: 0.667\n",
      "Train Epoch: 26 | Loss: 0.467 | Acc: 0.667\n",
      "Train Epoch: 27 | Loss: 0.453 | Acc: 0.667\n",
      "Train Epoch: 28 | Loss: 0.501 | Acc: 0.667\n",
      "Train Epoch: 29 | Loss: 0.422 | Acc: 0.667\n",
      "Train Epoch: 30 | Loss: 0.405 | Acc: 0.667\n",
      "saving....\n",
      "Train Epoch: 31 | Loss: 0.403 | Acc: 0.700\n",
      "Train Epoch: 32 | Loss: 0.387 | Acc: 0.720\n",
      "Train Epoch: 33 | Loss: 0.416 | Acc: 0.740\n",
      "Train Epoch: 34 | Loss: 0.398 | Acc: 0.760\n",
      "Train Epoch: 35 | Loss: 0.356 | Acc: 0.793\n",
      "Train Epoch: 36 | Loss: 0.392 | Acc: 0.813\n",
      "Train Epoch: 37 | Loss: 0.387 | Acc: 0.793\n",
      "Train Epoch: 38 | Loss: 0.383 | Acc: 0.827\n",
      "Train Epoch: 39 | Loss: 0.375 | Acc: 0.827\n",
      "Train Epoch: 40 | Loss: 0.367 | Acc: 0.827\n",
      "saving....\n",
      "Train Epoch: 41 | Loss: 0.376 | Acc: 0.813\n",
      "Train Epoch: 42 | Loss: 0.370 | Acc: 0.827\n",
      "saving....\n",
      "Train Epoch: 43 | Loss: 0.435 | Acc: 0.827\n",
      "Train Epoch: 44 | Loss: 0.421 | Acc: 0.833\n",
      "Train Epoch: 45 | Loss: 0.405 | Acc: 0.813\n",
      "Train Epoch: 46 | Loss: 0.367 | Acc: 0.820\n",
      "Train Epoch: 47 | Loss: 0.411 | Acc: 0.793\n",
      "Train Epoch: 48 | Loss: 0.329 | Acc: 0.827\n",
      "Train Epoch: 49 | Loss: 0.342 | Acc: 0.827\n",
      "Train Epoch: 50 | Loss: 0.348 | Acc: 0.833\n",
      "saving....\n",
      "Train Epoch: 51 | Loss: 0.343 | Acc: 0.820\n",
      "Train Epoch: 52 | Loss: 0.353 | Acc: 0.827\n",
      "Train Epoch: 53 | Loss: 0.335 | Acc: 0.813\n",
      "Train Epoch: 54 | Loss: 0.317 | Acc: 0.827\n",
      "Train Epoch: 55 | Loss: 0.346 | Acc: 0.827\n",
      "Train Epoch: 56 | Loss: 0.358 | Acc: 0.827\n",
      "Train Epoch: 57 | Loss: 0.364 | Acc: 0.820\n",
      "Train Epoch: 58 | Loss: 0.329 | Acc: 0.813\n",
      "Train Epoch: 59 | Loss: 0.341 | Acc: 0.820\n",
      "Train Epoch: 60 | Loss: 0.365 | Acc: 0.840\n",
      "saving....\n",
      "Train Epoch: 61 | Loss: 0.344 | Acc: 0.820\n",
      "Train Epoch: 62 | Loss: 0.362 | Acc: 0.833\n",
      "Train Epoch: 63 | Loss: 0.313 | Acc: 0.833\n",
      "Train Epoch: 64 | Loss: 0.321 | Acc: 0.840\n",
      "Train Epoch: 65 | Loss: 0.328 | Acc: 0.820\n",
      "Train Epoch: 66 | Loss: 0.392 | Acc: 0.840\n",
      "Train Epoch: 67 | Loss: 0.549 | Acc: 0.820\n",
      "Train Epoch: 68 | Loss: 0.605 | Acc: 0.807\n",
      "Train Epoch: 69 | Loss: 0.427 | Acc: 0.807\n",
      "Train Epoch: 70 | Loss: 0.372 | Acc: 0.827\n",
      "saving....\n",
      "Train Epoch: 71 | Loss: 0.408 | Acc: 0.807\n",
      "Train Epoch: 72 | Loss: 0.346 | Acc: 0.813\n",
      "Train Epoch: 73 | Loss: 0.388 | Acc: 0.840\n",
      "Train Epoch: 74 | Loss: 0.362 | Acc: 0.833\n",
      "Train Epoch: 75 | Loss: 0.299 | Acc: 0.853\n",
      "Train Epoch: 76 | Loss: 0.319 | Acc: 0.833\n",
      "Train Epoch: 77 | Loss: 0.308 | Acc: 0.833\n",
      "Train Epoch: 78 | Loss: 0.338 | Acc: 0.827\n",
      "Train Epoch: 79 | Loss: 0.364 | Acc: 0.833\n",
      "Train Epoch: 80 | Loss: 0.339 | Acc: 0.820\n",
      "saving....\n",
      "Train Epoch: 81 | Loss: 0.310 | Acc: 0.847\n",
      "Train Epoch: 82 | Loss: 0.280 | Acc: 0.867\n",
      "Train Epoch: 83 | Loss: 0.293 | Acc: 0.853\n",
      "Train Epoch: 84 | Loss: 0.298 | Acc: 0.860\n",
      "Train Epoch: 85 | Loss: 0.297 | Acc: 0.860\n",
      "Train Epoch: 86 | Loss: 0.280 | Acc: 0.867\n",
      "Train Epoch: 87 | Loss: 0.291 | Acc: 0.853\n",
      "Train Epoch: 88 | Loss: 0.274 | Acc: 0.860\n",
      "Train Epoch: 89 | Loss: 0.281 | Acc: 0.873\n",
      "Prototype 0 projected.\n",
      "Prototype 1 projected.\n",
      "Prototype 2 projected.\n",
      "Prototype 3 projected.\n",
      "Prototype 4 projected.\n",
      "Prototype 5 projected.\n",
      "Prototype 6 projected.\n",
      "Prototype 7 projected.\n",
      "Prototype 8 projected.\n",
      "Prototype 9 projected.\n",
      "Train Epoch: 90 | Loss: 0.367 | Acc: 0.840\n",
      "saving....\n",
      "Train Epoch: 91 | Loss: 0.255 | Acc: 0.873\n",
      "Train Epoch: 92 | Loss: 0.314 | Acc: 0.860\n",
      "Train Epoch: 93 | Loss: 0.285 | Acc: 0.860\n",
      "Train Epoch: 94 | Loss: 0.287 | Acc: 0.873\n",
      "Train Epoch: 95 | Loss: 0.276 | Acc: 0.873\n",
      "Train Epoch: 96 | Loss: 0.287 | Acc: 0.880\n",
      "Train Epoch: 97 | Loss: 0.267 | Acc: 0.880\n",
      "Train Epoch: 98 | Loss: 0.284 | Acc: 0.873\n",
      "Train Epoch: 99 | Loss: 0.236 | Acc: 0.887\n",
      "Train Epoch: 100 | Loss: 0.274 | Acc: 0.867\n",
      "saving....\n",
      "Train Epoch: 101 | Loss: 0.251 | Acc: 0.873\n",
      "Train Epoch: 102 | Loss: 0.292 | Acc: 0.873\n",
      "Train Epoch: 103 | Loss: 0.282 | Acc: 0.853\n",
      "Train Epoch: 104 | Loss: 0.330 | Acc: 0.840\n",
      "Prototype 0 projected.\n",
      "Prototype 1 projected.\n",
      "Prototype 2 projected.\n",
      "Prototype 3 projected.\n",
      "Prototype 4 projected.\n",
      "Prototype 5 projected.\n",
      "Prototype 6 projected.\n",
      "Prototype 7 projected.\n",
      "Prototype 8 projected.\n",
      "Prototype 9 projected.\n",
      "Train Epoch: 105 | Loss: 0.332 | Acc: 0.847\n",
      "Train Epoch: 106 | Loss: 0.362 | Acc: 0.893\n",
      "Train Epoch: 107 | Loss: 0.331 | Acc: 0.833\n",
      "Train Epoch: 108 | Loss: 0.317 | Acc: 0.853\n",
      "Train Epoch: 109 | Loss: 0.328 | Acc: 0.887\n",
      "Train Epoch: 110 | Loss: 0.277 | Acc: 0.860\n",
      "saving....\n",
      "Train Epoch: 111 | Loss: 0.287 | Acc: 0.847\n",
      "Train Epoch: 112 | Loss: 0.246 | Acc: 0.873\n",
      "Train Epoch: 113 | Loss: 0.268 | Acc: 0.873\n",
      "Train Epoch: 114 | Loss: 0.261 | Acc: 0.860\n",
      "Train Epoch: 115 | Loss: 0.213 | Acc: 0.900\n",
      "Train Epoch: 116 | Loss: 0.215 | Acc: 0.860\n",
      "Train Epoch: 117 | Loss: 0.284 | Acc: 0.867\n",
      "Train Epoch: 118 | Loss: 0.276 | Acc: 0.867\n",
      "Train Epoch: 119 | Loss: 0.308 | Acc: 0.860\n",
      "Prototype 0 projected.\n",
      "Prototype 1 projected.\n",
      "Prototype 2 projected.\n",
      "Prototype 3 projected.\n",
      "Prototype 4 projected.\n",
      "Prototype 5 projected.\n",
      "Prototype 6 projected.\n",
      "Prototype 7 projected.\n",
      "Prototype 8 projected.\n",
      "Prototype 9 projected.\n",
      "Train Epoch: 120 | Loss: 0.337 | Acc: 0.833\n",
      "saving....\n",
      "Train Epoch: 121 | Loss: 0.298 | Acc: 0.840\n",
      "Train Epoch: 122 | Loss: 0.263 | Acc: 0.860\n",
      "Train Epoch: 123 | Loss: 0.220 | Acc: 0.880\n",
      "Train Epoch: 124 | Loss: 0.258 | Acc: 0.853\n",
      "Train Epoch: 125 | Loss: 0.264 | Acc: 0.880\n",
      "Train Epoch: 126 | Loss: 0.232 | Acc: 0.873\n",
      "Train Epoch: 127 | Loss: 0.260 | Acc: 0.873\n",
      "Train Epoch: 128 | Loss: 0.243 | Acc: 0.873\n",
      "saving....\n",
      "Train Epoch: 129 | Loss: 0.226 | Acc: 0.880\n",
      "Train Epoch: 130 | Loss: 0.201 | Acc: 0.900\n",
      "saving....\n",
      "Train Epoch: 131 | Loss: 0.230 | Acc: 0.880\n",
      "Train Epoch: 132 | Loss: 0.197 | Acc: 0.880\n",
      "Train Epoch: 133 | Loss: 0.204 | Acc: 0.893\n",
      "Train Epoch: 134 | Loss: 0.202 | Acc: 0.887\n",
      "Prototype 0 projected.\n",
      "Prototype 1 projected.\n",
      "Prototype 2 projected.\n",
      "Prototype 3 projected.\n",
      "Prototype 4 projected.\n",
      "Prototype 5 projected.\n",
      "Prototype 6 projected.\n",
      "Prototype 7 projected.\n",
      "Prototype 8 projected.\n",
      "Prototype 9 projected.\n",
      "Train Epoch: 135 | Loss: 0.256 | Acc: 0.873\n",
      "Train Epoch: 136 | Loss: 0.203 | Acc: 0.887\n",
      "Train Epoch: 137 | Loss: 0.225 | Acc: 0.873\n",
      "Train Epoch: 138 | Loss: 0.209 | Acc: 0.887\n",
      "Train Epoch: 139 | Loss: 0.212 | Acc: 0.880\n",
      "Train Epoch: 140 | Loss: 0.240 | Acc: 0.873\n",
      "saving....\n",
      "Train Epoch: 141 | Loss: 0.261 | Acc: 0.867\n",
      "Train Epoch: 142 | Loss: 0.220 | Acc: 0.887\n",
      "Train Epoch: 143 | Loss: 0.250 | Acc: 0.860\n",
      "Train Epoch: 144 | Loss: 0.254 | Acc: 0.867\n",
      "Train Epoch: 145 | Loss: 0.201 | Acc: 0.893\n",
      "Train Epoch: 146 | Loss: 0.208 | Acc: 0.893\n",
      "Train Epoch: 147 | Loss: 0.179 | Acc: 0.873\n",
      "Train Epoch: 148 | Loss: 0.165 | Acc: 0.887\n",
      "Train Epoch: 149 | Loss: 0.165 | Acc: 0.893\n",
      "Prototype 0 projected.\n",
      "Prototype 1 projected.\n",
      "Prototype 2 projected.\n",
      "Prototype 3 projected.\n",
      "Prototype 4 projected.\n",
      "Prototype 5 projected.\n",
      "Prototype 6 projected.\n",
      "Prototype 7 projected.\n",
      "Prototype 8 projected.\n",
      "Prototype 9 projected.\n",
      "Train Epoch: 150 | Loss: 0.208 | Acc: 0.887\n",
      "saving....\n",
      "Train Epoch: 151 | Loss: 0.203 | Acc: 0.853\n",
      "Train Epoch: 152 | Loss: 0.238 | Acc: 0.860\n",
      "Train Epoch: 153 | Loss: 0.202 | Acc: 0.887\n",
      "Train Epoch: 154 | Loss: 0.205 | Acc: 0.887\n",
      "Train Epoch: 155 | Loss: 0.234 | Acc: 0.887\n",
      "Train Epoch: 156 | Loss: 0.266 | Acc: 0.853\n",
      "Train Epoch: 157 | Loss: 0.287 | Acc: 0.867\n",
      "Train Epoch: 158 | Loss: 0.262 | Acc: 0.860\n",
      "Train Epoch: 159 | Loss: 0.261 | Acc: 0.860\n",
      "Train Epoch: 160 | Loss: 0.214 | Acc: 0.867\n",
      "saving....\n",
      "Train Epoch: 161 | Loss: 0.208 | Acc: 0.887\n",
      "Train Epoch: 162 | Loss: 0.205 | Acc: 0.887\n",
      "Train Epoch: 163 | Loss: 0.196 | Acc: 0.880\n",
      "Train Epoch: 164 | Loss: 0.197 | Acc: 0.880\n",
      "Prototype 0 projected.\n",
      "Prototype 1 projected.\n",
      "Prototype 2 projected.\n",
      "Prototype 3 projected.\n",
      "Prototype 4 projected.\n",
      "Prototype 5 projected.\n",
      "Prototype 6 projected.\n",
      "Prototype 7 projected.\n",
      "Prototype 8 projected.\n",
      "Prototype 9 projected.\n",
      "Train Epoch: 165 | Loss: 0.236 | Acc: 0.873\n",
      "Train Epoch: 166 | Loss: 0.207 | Acc: 0.893\n",
      "Train Epoch: 167 | Loss: 0.216 | Acc: 0.887\n",
      "Train Epoch: 168 | Loss: 0.197 | Acc: 0.880\n",
      "Train Epoch: 169 | Loss: 0.208 | Acc: 0.880\n",
      "Train Epoch: 170 | Loss: 0.202 | Acc: 0.893\n",
      "saving....\n",
      "Train Epoch: 171 | Loss: 0.177 | Acc: 0.893\n",
      "Train Epoch: 172 | Loss: 0.203 | Acc: 0.880\n",
      "Train Epoch: 173 | Loss: 0.215 | Acc: 0.887\n",
      "Train Epoch: 174 | Loss: 0.225 | Acc: 0.880\n",
      "Train Epoch: 175 | Loss: 0.197 | Acc: 0.880\n",
      "Train Epoch: 176 | Loss: 0.214 | Acc: 0.867\n",
      "Train Epoch: 177 | Loss: 0.316 | Acc: 0.880\n",
      "Train Epoch: 178 | Loss: 0.263 | Acc: 0.820\n",
      "Train Epoch: 179 | Loss: 0.304 | Acc: 0.827\n",
      "Prototype 0 projected.\n",
      "Prototype 1 projected.\n",
      "Prototype 2 projected.\n",
      "Prototype 3 projected.\n",
      "Prototype 4 projected.\n",
      "Prototype 5 projected.\n",
      "Prototype 6 projected.\n",
      "Prototype 7 projected.\n",
      "Prototype 8 projected.\n",
      "Prototype 9 projected.\n",
      "Train Epoch: 180 | Loss: 0.204 | Acc: 0.900\n",
      "saving....\n",
      "Train Epoch: 181 | Loss: 0.239 | Acc: 0.860\n",
      "Train Epoch: 182 | Loss: 0.216 | Acc: 0.893\n",
      "Train Epoch: 183 | Loss: 0.198 | Acc: 0.893\n",
      "Train Epoch: 184 | Loss: 0.201 | Acc: 0.887\n",
      "Train Epoch: 185 | Loss: 0.283 | Acc: 0.847\n",
      "Train Epoch: 186 | Loss: 0.284 | Acc: 0.827\n",
      "Train Epoch: 187 | Loss: 0.195 | Acc: 0.907\n",
      "Train Epoch: 188 | Loss: 0.231 | Acc: 0.887\n",
      "Train Epoch: 189 | Loss: 0.311 | Acc: 0.887\n",
      "saving....\n",
      "Train Epoch: 190 | Loss: 0.293 | Acc: 0.827\n",
      "saving....\n",
      "Train Epoch: 191 | Loss: 0.259 | Acc: 0.873\n",
      "Train Epoch: 192 | Loss: 0.200 | Acc: 0.907\n",
      "Train Epoch: 193 | Loss: 0.225 | Acc: 0.900\n",
      "Train Epoch: 194 | Loss: 0.220 | Acc: 0.887\n",
      "Prototype 0 projected.\n",
      "Prototype 1 projected.\n",
      "Prototype 2 projected.\n",
      "Prototype 3 projected.\n",
      "Prototype 4 projected.\n",
      "Prototype 5 projected.\n",
      "Prototype 6 projected.\n",
      "Prototype 7 projected.\n",
      "Prototype 8 projected.\n",
      "Prototype 9 projected.\n",
      "Train Epoch: 195 | Loss: 0.269 | Acc: 0.873\n",
      "Train Epoch: 196 | Loss: 0.223 | Acc: 0.900\n",
      "Train Epoch: 197 | Loss: 0.197 | Acc: 0.913\n",
      "Train Epoch: 198 | Loss: 0.249 | Acc: 0.893\n",
      "Train Epoch: 199 | Loss: 0.322 | Acc: 0.827\n",
      "Train Epoch: 200 | Loss: 0.268 | Acc: 0.887\n",
      "saving....\n",
      "Train Epoch: 201 | Loss: 0.231 | Acc: 0.893\n",
      "Train Epoch: 202 | Loss: 0.208 | Acc: 0.887\n",
      "Train Epoch: 203 | Loss: 0.189 | Acc: 0.887\n",
      "Train Epoch: 204 | Loss: 0.179 | Acc: 0.907\n",
      "Train Epoch: 205 | Loss: 0.183 | Acc: 0.900\n",
      "Train Epoch: 206 | Loss: 0.183 | Acc: 0.893\n",
      "Train Epoch: 207 | Loss: 0.188 | Acc: 0.893\n",
      "Train Epoch: 208 | Loss: 0.182 | Acc: 0.907\n",
      "Train Epoch: 209 | Loss: 0.191 | Acc: 0.900\n",
      "Prototype 0 projected.\n",
      "Prototype 1 projected.\n",
      "Prototype 2 projected.\n",
      "Prototype 3 projected.\n",
      "Prototype 4 projected.\n",
      "Prototype 5 projected.\n",
      "Prototype 6 projected.\n",
      "Prototype 7 projected.\n",
      "Prototype 8 projected.\n",
      "Prototype 9 projected.\n",
      "Train Epoch: 210 | Loss: 0.173 | Acc: 0.907\n",
      "saving....\n",
      "Train Epoch: 211 | Loss: 0.186 | Acc: 0.907\n",
      "Train Epoch: 212 | Loss: 0.160 | Acc: 0.900\n",
      "Train Epoch: 213 | Loss: 0.171 | Acc: 0.893\n",
      "Train Epoch: 214 | Loss: 0.180 | Acc: 0.893\n",
      "Train Epoch: 215 | Loss: 0.210 | Acc: 0.913\n",
      "Train Epoch: 216 | Loss: 0.285 | Acc: 0.887\n",
      "Train Epoch: 217 | Loss: 0.235 | Acc: 0.900\n",
      "Train Epoch: 218 | Loss: 0.241 | Acc: 0.887\n",
      "Train Epoch: 219 | Loss: 0.225 | Acc: 0.927\n",
      "Train Epoch: 220 | Loss: 0.215 | Acc: 0.907\n",
      "saving....\n",
      "Train Epoch: 221 | Loss: 0.192 | Acc: 0.893\n",
      "Train Epoch: 222 | Loss: 0.196 | Acc: 0.880\n",
      "Train Epoch: 223 | Loss: 0.188 | Acc: 0.880\n",
      "Train Epoch: 224 | Loss: 0.177 | Acc: 0.913\n",
      "Prototype 0 projected.\n",
      "Prototype 1 projected.\n",
      "Prototype 2 projected.\n",
      "Prototype 3 projected.\n",
      "Prototype 4 projected.\n",
      "Prototype 5 projected.\n",
      "Prototype 6 projected.\n",
      "Prototype 7 projected.\n",
      "Prototype 8 projected.\n",
      "Prototype 9 projected.\n",
      "Train Epoch: 225 | Loss: 0.173 | Acc: 0.907\n",
      "Train Epoch: 226 | Loss: 0.154 | Acc: 0.940\n",
      "Train Epoch: 227 | Loss: 0.272 | Acc: 0.900\n",
      "Train Epoch: 228 | Loss: 0.369 | Acc: 0.860\n",
      "Train Epoch: 229 | Loss: 0.342 | Acc: 0.867\n",
      "Train Epoch: 230 | Loss: 0.297 | Acc: 0.893\n",
      "saving....\n",
      "Train Epoch: 231 | Loss: 0.273 | Acc: 0.880\n",
      "Train Epoch: 232 | Loss: 0.300 | Acc: 0.900\n",
      "Train Epoch: 233 | Loss: 0.209 | Acc: 0.900\n",
      "Train Epoch: 234 | Loss: 0.174 | Acc: 0.927\n",
      "Train Epoch: 235 | Loss: 0.175 | Acc: 0.900\n",
      "Train Epoch: 236 | Loss: 0.158 | Acc: 0.920\n",
      "Train Epoch: 237 | Loss: 0.147 | Acc: 0.913\n",
      "Train Epoch: 238 | Loss: 0.156 | Acc: 0.913\n",
      "Train Epoch: 239 | Loss: 0.166 | Acc: 0.920\n",
      "Prototype 0 projected.\n",
      "Prototype 1 projected.\n",
      "Prototype 2 projected.\n",
      "Prototype 3 projected.\n",
      "Prototype 4 projected.\n",
      "Prototype 5 projected.\n",
      "Prototype 6 projected.\n",
      "Prototype 7 projected.\n",
      "Prototype 8 projected.\n",
      "Prototype 9 projected.\n",
      "Train Epoch: 240 | Loss: 0.192 | Acc: 0.913\n",
      "saving....\n",
      "Train Epoch: 241 | Loss: 0.221 | Acc: 0.893\n",
      "Train Epoch: 242 | Loss: 0.185 | Acc: 0.893\n",
      "Train Epoch: 243 | Loss: 0.162 | Acc: 0.900\n",
      "Train Epoch: 244 | Loss: 0.132 | Acc: 0.913\n",
      "Train Epoch: 245 | Loss: 0.127 | Acc: 0.940\n",
      "Train Epoch: 246 | Loss: 0.105 | Acc: 0.933\n",
      "Train Epoch: 247 | Loss: 0.138 | Acc: 0.927\n",
      "Train Epoch: 248 | Loss: 0.118 | Acc: 0.940\n",
      "Train Epoch: 249 | Loss: 0.133 | Acc: 0.960\n",
      "Train Epoch: 250 | Loss: 0.141 | Acc: 0.947\n",
      "saving....\n",
      "Train Epoch: 251 | Loss: 0.132 | Acc: 0.960\n",
      "Train Epoch: 252 | Loss: 0.099 | Acc: 0.947\n",
      "Train Epoch: 253 | Loss: 0.149 | Acc: 0.927\n",
      "Train Epoch: 254 | Loss: 0.184 | Acc: 0.960\n",
      "Prototype 0 projected.\n",
      "Prototype 1 projected.\n",
      "Prototype 2 projected.\n",
      "Prototype 3 projected.\n",
      "Prototype 4 projected.\n",
      "Prototype 5 projected.\n",
      "Prototype 6 projected.\n",
      "Prototype 7 projected.\n",
      "Prototype 8 projected.\n",
      "Prototype 9 projected.\n",
      "Train Epoch: 255 | Loss: 0.149 | Acc: 0.960\n",
      "Train Epoch: 256 | Loss: 0.170 | Acc: 0.927\n",
      "Train Epoch: 257 | Loss: 0.138 | Acc: 0.927\n",
      "Train Epoch: 258 | Loss: 0.229 | Acc: 0.907\n",
      "Train Epoch: 259 | Loss: 0.414 | Acc: 0.860\n",
      "Train Epoch: 260 | Loss: 0.351 | Acc: 0.867\n",
      "saving....\n",
      "Train Epoch: 261 | Loss: 0.270 | Acc: 0.927\n",
      "Train Epoch: 262 | Loss: 0.213 | Acc: 0.907\n",
      "Train Epoch: 263 | Loss: 0.175 | Acc: 0.933\n",
      "Train Epoch: 264 | Loss: 0.217 | Acc: 0.940\n",
      "Train Epoch: 265 | Loss: 0.183 | Acc: 0.933\n",
      "Train Epoch: 266 | Loss: 0.150 | Acc: 0.920\n",
      "Train Epoch: 267 | Loss: 0.133 | Acc: 0.960\n",
      "Train Epoch: 268 | Loss: 0.123 | Acc: 0.953\n",
      "Train Epoch: 269 | Loss: 0.245 | Acc: 0.933\n",
      "Prototype 0 projected.\n",
      "Prototype 1 projected.\n",
      "Prototype 2 projected.\n",
      "Prototype 3 projected.\n",
      "Prototype 4 projected.\n",
      "Prototype 5 projected.\n",
      "Prototype 6 projected.\n",
      "Prototype 7 projected.\n",
      "Prototype 8 projected.\n",
      "Prototype 9 projected.\n",
      "Train Epoch: 270 | Loss: 0.192 | Acc: 0.920\n",
      "saving....\n",
      "The best validation accuracy is 0.9444\n",
      "====================Testing==================\n",
      "Test: | Loss: 0.509 | Acc: 0.700\n",
      "====================Generating Explanations====================\n",
      "[1, 2, 3, 4, 5, 7, 8, 9, 11, 12]\n",
      "[2, 3, 7, 8, 9, 11, 12, 13, 14, 15]\n",
      "[1, 2, 3, 4, 5, 7, 8, 9, 11, 12]\n",
      "[1, 2, 7, 8, 9, 11, 12, 13, 14, 15]\n",
      "[7, 8, 9, 10, 11, 13, 14, 15]\n",
      "[1, 2, 3, 4, 5, 7, 8, 9, 11, 12]\n",
      "[1, 2, 3, 4, 5, 7, 8, 9, 11, 12]\n",
      "[2, 3, 7, 8, 9, 11, 12, 13, 14, 15]\n",
      "[1, 2, 7, 8, 10, 11, 12, 13, 14, 15]\n",
      "[1, 2, 3, 4, 5, 7, 8, 9, 11, 12]\n",
      "[0, 1, 2, 3, 4, 5, 7, 8, 9]\n",
      "[0, 1, 2, 3, 4, 5, 7, 8, 9]\n",
      "[0, 1, 2, 3, 4, 5, 7, 8, 9, 10]\n",
      "[0, 1, 2, 3, 4, 5, 7, 8, 9]\n",
      "[0, 1, 3, 4, 5, 7, 8, 9]\n",
      "[0, 1, 2, 3, 4, 5, 7, 8, 9]\n",
      "[0, 1, 2, 3, 4, 5, 7, 8, 9, 10]\n",
      "[0, 1, 2, 3, 4, 5, 7, 8, 9]\n",
      "[0, 1, 3, 4, 5, 7, 8, 9]\n",
      "[0, 1, 2, 3, 4, 5, 7, 8, 9]\n",
      "[0, 1, 2, 4, 5, 6, 7, 8, 11]\n",
      "[0, 1, 2, 5, 6, 7, 8, 10, 11]\n",
      "[0, 1, 2, 3, 5, 6, 7, 8, 11]\n",
      "[0, 1, 2, 3, 5, 6, 7, 8, 9, 11]\n",
      "[0, 1, 2, 3, 5, 6, 7, 8, 11]\n",
      "[0, 1, 2, 3, 5, 6, 7, 8, 11]\n",
      "[0, 1, 2, 3, 5, 6, 7, 8, 10, 11]\n",
      "[0, 1, 2, 3, 5, 6, 7, 8, 11]\n",
      "[0, 1, 2, 4, 5, 6, 7, 8, 11]\n",
      "[0, 1, 2, 5, 6, 7, 8, 10, 11]\n",
      "[2, 4, 5, 6, 7, 8, 9, 13, 14, 15]\n",
      "[2, 4, 5, 6, 7, 8, 9, 13, 14, 15]\n",
      "[2, 4, 5, 6, 7, 8, 9, 13, 14, 15]\n",
      "[2, 6, 7, 8, 9, 11, 12, 13, 14, 15]\n",
      "[2, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "[2, 6, 7, 8, 9, 11, 12, 13, 14, 15]\n",
      "[0, 6, 7, 8, 9, 10, 12, 13, 14, 15]\n",
      "[2, 4, 5, 6, 7, 8, 9, 13, 14, 15]\n",
      "[2, 4, 5, 6, 7, 8, 9, 13, 14, 15]\n",
      "[2, 4, 5, 6, 7, 8, 9, 13, 14, 15]\n",
      "[1, 2, 3, 4, 5, 8, 9, 10, 11, 12]\n",
      "[1, 2, 3, 4, 5, 8, 9, 10, 11, 12]\n",
      "[1, 2, 3, 4, 5, 7, 8, 9]\n",
      "[1, 2, 3, 4, 5, 7, 8, 9]\n",
      "[1, 2, 3, 4, 5, 7, 8, 9]\n",
      "[1, 2, 3, 4, 5, 7, 8, 9]\n",
      "[1, 2, 3, 4, 5, 8, 9, 10, 11, 12]\n",
      "[1, 2, 3, 4, 5, 7, 8, 9]\n",
      "[4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "[0, 1, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "[0, 1, 4, 5, 6, 7, 13, 17, 18, 19]\n",
      "[0, 1, 3, 4, 5, 6, 7, 17, 18, 19]\n",
      "[0, 4, 5, 7, 9, 10, 11, 12, 13]\n",
      "[0, 4, 5, 7, 8, 9, 11, 12, 13, 15]\n",
      "[0, 1, 5, 6, 7, 12, 13, 17, 18, 19]\n",
      "[3, 4, 5, 6, 7, 9, 10, 11, 12, 13]\n",
      "[0, 1, 4, 5, 6, 12, 13, 17, 18, 19]\n",
      "[0, 4, 5, 7, 8, 9, 11, 12, 13]\n",
      "[0, 1, 4, 5, 6, 12, 13, 17, 18, 19]\n",
      "[2, 3, 4, 5, 6, 7, 10, 11, 12, 13]\n",
      "[0, 2, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "[0, 1, 2, 5, 6, 7, 8, 9, 10, 11]\n",
      "[1, 2, 3, 5, 6, 7, 8, 9, 10, 11]\n",
      "[0, 1, 2, 5, 6, 7, 8, 9, 10, 11]\n",
      "[2, 3, 4, 5, 7, 8, 9, 12, 13, 14]\n",
      "[0, 1, 2, 5, 6, 7, 8, 9, 10, 11]\n",
      "[1, 2, 3, 5, 6, 7, 8, 9, 10, 11]\n",
      "[0, 1, 2, 5, 6, 7, 8, 9, 10, 11]\n",
      "[1, 2, 3, 5, 6, 7, 8, 9, 10, 11]\n",
      "[0, 2, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "[6, 10, 11, 12, 13, 15, 16, 17, 18, 19]\n",
      "[6, 10, 11, 12, 13, 15, 16, 17, 18, 19]\n",
      "[6, 10, 11, 12, 13, 15, 16, 17, 18, 19]\n",
      "[6, 8, 9, 10, 11, 12, 13, 17, 18, 19]\n",
      "[6, 8, 9, 10, 11, 12, 13, 17, 18, 19]\n",
      "[6, 8, 9, 10, 11, 12, 13, 17, 18, 19]\n",
      "[6, 8, 9, 10, 11, 12, 13, 17, 18, 19]\n",
      "[6, 10, 11, 12, 13, 15, 16, 17, 18, 19]\n",
      "[6, 10, 11, 12, 13, 15, 16, 17, 18, 19]\n",
      "[6, 10, 11, 12, 13, 15, 16, 17, 18, 19]\n",
      "[10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[11, 13, 14, 15, 16, 17, 18, 19]\n",
      "[11, 13, 14, 15, 16, 17, 18, 19]\n",
      "[11, 13, 14, 15, 16, 17, 18, 19]\n",
      "[11, 13, 14, 15, 16, 17, 18, 19]\n",
      "[11, 13, 14, 15, 16, 17, 18, 19]\n",
      "[2, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[11, 13, 14, 15, 16, 17, 18, 19]\n",
      "[11, 13, 14, 15, 16, 17, 18, 19]\n",
      "[11, 13, 14, 15, 16, 17, 18, 19]\n",
      "[2, 3, 4, 5, 9, 10, 11, 12, 14, 15]\n",
      "[2, 3, 4, 5, 9, 10, 11, 12, 14, 15]\n",
      "[2, 3, 4, 9, 10, 11, 12, 13, 14, 15]\n",
      "[2, 3, 4, 5, 6, 7, 8, 10, 11, 15]\n",
      "[3, 9, 10, 11, 12, 14, 15, 16]\n",
      "[2, 3, 4, 9, 10, 11, 12, 13, 14, 15]\n",
      "[2, 3, 4, 5, 9, 10, 11, 12, 14, 15]\n",
      "[2, 3, 4, 9, 10, 11, 12, 13, 14, 15]\n",
      "[0, 1, 2, 3, 4, 9, 10, 11, 12, 15]\n",
      "[2, 3, 4, 9, 10, 11, 12, 13, 14, 15]\n",
      "[5, 6, 8, 9, 10, 11, 12, 13, 14]\n",
      "[0, 1, 5, 6, 9, 10, 11, 12, 13, 14]\n",
      "[0, 1, 5, 6, 9, 10, 11, 12, 13, 14]\n",
      "[3, 4, 5, 6, 9, 10, 11, 12, 13, 14]\n",
      "[0, 5, 6, 9, 10, 11, 12, 13, 14]\n",
      "[3, 4, 5, 6, 9, 10, 11, 12, 13, 14]\n",
      "[5, 6, 8, 9, 10, 11, 12, 13, 14]\n",
      "[0, 4, 5, 6, 9, 10, 11, 12, 13, 14]\n",
      "[5, 6, 8, 9, 10, 11, 12, 13, 14]\n",
      "[0, 1, 5, 6, 9, 10, 11, 12, 13, 14]\n",
      "[0, 1, 2, 3, 4, 6, 7, 10, 11, 12]\n",
      "[0, 1, 2, 3, 4, 6, 7, 10, 11, 12]\n",
      "[0, 1, 2, 3, 4, 6, 7, 10, 11, 12]\n",
      "[0, 1, 2, 3, 4, 6, 7, 10, 11, 12]\n",
      "[0, 1, 2, 3, 4, 6, 7, 10, 11, 12]\n",
      "[0, 1, 2, 3, 4, 6, 7, 10, 11, 12]\n",
      "[0, 1, 2, 3, 4, 6, 7, 10, 11, 12]\n",
      "[0, 1, 2, 3, 4, 6, 7, 10, 11, 12]\n",
      "[0, 1, 2, 4, 5, 6, 7, 10, 11, 12]\n",
      "[0, 1, 2, 3, 4, 6, 7, 10, 11, 12]\n",
      "[3, 4, 6, 7, 8, 10, 11, 12, 13, 14]\n",
      "[6, 8, 9, 10, 11, 12, 14, 15, 16]\n",
      "[4, 6, 7, 8, 9, 10, 11, 12, 13, 15]\n",
      "[7, 8, 9, 10, 11, 12, 13, 19, 20, 21]\n",
      "[3, 4, 6, 7, 8, 10, 11, 12, 13, 14]\n",
      "[6, 8, 9, 10, 11, 12, 14, 15, 16]\n",
      "[3, 4, 6, 7, 8, 10, 11, 12, 13, 14]\n",
      "[6, 8, 9, 10, 11, 12, 14, 15, 16]\n",
      "[3, 4, 6, 7, 8, 10, 11, 12, 13, 19]\n",
      "[6, 8, 9, 10, 11, 12, 14, 15, 16]\n",
      "[3, 6, 10, 11, 12, 13, 14, 16, 17, 18]\n",
      "[3, 6, 10, 11, 12, 13, 14, 16, 17, 18]\n",
      "[3, 6, 10, 11, 12, 13, 14, 16, 17, 18]\n",
      "[3, 6, 10, 11, 12, 13, 14, 16, 17, 18]\n",
      "[3, 6, 10, 11, 12, 13, 14, 16, 17, 18]\n",
      "[3, 6, 10, 11, 12, 13, 14, 16, 17, 18]\n",
      "[3, 6, 10, 11, 12, 13, 16, 17, 18, 20]\n",
      "[3, 6, 10, 11, 12, 13, 14, 16, 17, 18]\n",
      "[3, 6, 10, 11, 12, 13, 14, 16, 17, 18]\n",
      "[6, 10, 11, 12, 13, 14, 16, 17, 18]\n",
      "[2, 3, 4, 5, 6, 7, 8, 9, 13, 15]\n",
      "[2, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "[2, 3, 4, 5, 6, 7, 8, 9, 13, 15]\n",
      "[2, 3, 4, 5, 6, 7, 8, 9, 13, 15]\n",
      "[6, 8, 12, 13, 14, 15, 18, 19]\n",
      "[5, 6, 7, 13, 14, 15, 16, 17, 19]\n",
      "[5, 6, 7, 13, 14, 15, 16, 17, 18, 19]\n",
      "[2, 3, 4, 5, 6, 7, 8, 9, 13, 15]\n",
      "[2, 3, 4, 5, 6, 7, 8, 9, 13, 15]\n",
      "[5, 6, 7, 13, 14, 15, 16, 17, 18, 19]\n",
      "[2, 3, 4, 5, 6, 7, 8, 9, 10, 16]\n",
      "[2, 3, 4, 10, 12, 13, 14, 15, 16, 17]\n",
      "[1, 2, 3, 4, 5, 10, 11, 14, 15, 16]\n",
      "[2, 3, 4, 5, 9, 10, 11, 12, 15, 16]\n",
      "[1, 2, 3, 4, 5, 10, 11, 14, 15, 16]\n",
      "[2, 3, 4, 5, 9, 10, 11, 12, 15, 16]\n",
      "[2, 3, 4, 10, 12, 13, 14, 15, 16, 17]\n",
      "[2, 3, 4, 5, 9, 10, 11, 12, 15, 16]\n",
      "[0, 1, 2, 3, 5, 10, 11, 12, 15, 16]\n",
      "[2, 3, 4, 5, 9, 10, 11, 12, 15, 16]\n"
     ]
    }
   ],
   "source": [
    "class Args:\n",
    "    clst = 0.0  # cluster loss weight\n",
    "    sep = 0.0   # separation loss weight\n",
    "\n",
    "args = Args()\n",
    "main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7feedf6",
   "metadata": {},
   "source": [
    "### Sampled Explanations (MUTAG Dataset)\n",
    "\n",
    "The MUTAG dataset contains molecular graphs of nitroaromatic compounds labeled by mutagenicity. Our model is trained to extract **prototype subgraphs** (i.e., key explanatory regions) that ideally align with known mutagenic structures, such as **NO<sub>2</sub> groups (nitro) attached to aromatic rings**.\n",
    "\n",
    "Below, we present three randomly selected prototype subgraphs from the model's output. Each image shows the full molecular graph, with **bolded edges representing the key subgraph** extracted by the model. These visualizations allow us to assess whether the model accurately isolates chemically meaningful explanations.\n",
    "\n",
    "---\n",
    "\n",
    "**Figure 1: Ground-truth explanation successfully captured**  \n",
    "_Example 40 - from results folder_  \n",
    "![Figure 1](./sampled_explanations/example_40_sampled.png)\n",
    "\n",
    "- The bolded subgraph includes the **NO<sub>2</sub> group** and part of a **fused aromatic ring**, both known to correlate with mutagenicity.\n",
    "- This explanation aligns strongly with ground-truth domain knowledge.\n",
    "- A high-quality prototype and interpretability success case.\n",
    "\n",
    "---\n",
    "\n",
    "**Figure 2: Excessive C-C edge and missing one N-O edge**  \n",
    "_Example 19 - from results folder_  \n",
    "![Figure 2](./sampled_explanations/example_19_sampled.png)\n",
    "\n",
    "- The model **misses one of the N-O bonds** in the nitro group.\n",
    "- It also includes an **extra C-C bond** that is not chemically relevant to the mutagenic substructure.\n",
    "- This indicates **partial faithfulness** - the model recognizes the general area of importance but fails to precisely localize the explanation.\n",
    "\n",
    "---\n",
    "\n",
    "**Figure 3: Partial capture of mutagenic structure**  \n",
    "_Example 202 - from results folder_  \n",
    "![Figure 3](./sampled_explanations/example_202_sampled.png)\n",
    "\n",
    "- The molecule contains **two NO<sub>2</sub> groups**, but only one is captured in the bolded subgraph.\n",
    "- The highlighted region covers part of the upper aromatic ring, omitting the second relevant NO<sub>2</sub> group.\n",
    "- Suggests either subgraph size limitations or model uncertainty in explanation coverage.\n",
    "\n",
    "---\n",
    "\n",
    "### Summary\n",
    "\n",
    "| Example      | Model Behavior                                             | Qualitative Assessment                |\n",
    "|--------------|------------------------------------------------------------|---------------------------|\n",
    "| `example_40` | Captures NO<sub>2</sub> and aromatic ring (true explanation)  | Ground-truth aligned   |\n",
    "| `example_19` | Misses N-O edge, includes irrelevant C-C edge              | Imperfect explanation  |\n",
    "| `example_202`| Captures only one NO<sub>2</sub> group, misses a second key region | Partial coverage       |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "protgnn_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

\documentclass[12pt, titlepage]{article}

\usepackage{amsmath, mathtools}

\usepackage[round]{natbib}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{colortbl}
\usepackage{xr}
\usepackage{hyperref}
\usepackage{longtable}
\usepackage{xfrac}
\usepackage{tabularx}
\usepackage{float}
\usepackage{siunitx}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage[section]{placeins}
\usepackage{caption}
\usepackage{fullpage}

\hypersetup{
bookmarks=true,     % show bookmarks bar?
colorlinks=true,       % false: boxed links; true: colored links
linkcolor=red,          % color of internal links (change box color with linkbordercolor)
citecolor=blue,      % color of links to bibliography
filecolor=magenta,  % color of file links
urlcolor=cyan          % color of external links
}

\usepackage{array}

\externaldocument{../../SRS/SRS}

\input{../../Comments}
\input{../../Common}

\begin{document}

\title{Module Interface Specification for Re-ProtGNN}

\author{\authname}

\date{\today}

\maketitle

\pagenumbering{roman}

\section{Revision History}

\begin{tabularx}{\textwidth}{p{3cm}p{2cm}X}
\toprule {\bf Date} & {\bf Version} & {\bf Notes}\\
\midrule
Mar 19, 2025 & 1.0 & Initial Draft\\
\bottomrule
\end{tabularx}

~\newpage

\section{Symbols, Abbreviations and Acronyms}

See SRS Documentation at \url{https://github.com/Yuanqi-X/Re-ProtGNN/blob/main/docs/SRS/SRS.pdf}.

\newpage

\tableofcontents

\newpage

\pagenumbering{arabic}

\section{Introduction}

The following document details the Module Interface Specifications for Re-ProtGNN, a re-implementation of an interpretable Graph Neural Network (GNN) Framework.

Complementary documents include the System Requirement Specifications
and Module Guide.  The full documentation and implementation can be
found at \url{https://github.com/Yuanqi-X/Re-ProtGNN/tree/main}.

\section{Notation}

The structure of the MIS for modules comes from \citet{HoffmanAndStrooper1995},
with the addition that template modules have been adapted from
\cite{GhezziEtAl2003}.  The mathematical notation comes from Chapter 3 of
\citet{HoffmanAndStrooper1995}.  For instance, the symbol := is used for a
multiple assignment statement and conditional rules follow the form $(c_1
\Rightarrow r_1 | c_2 \Rightarrow r_2 | ... | c_n \Rightarrow r_n )$.

The following table summarizes the primitive data types used by Re-ProtGNN. 

\begin{center}
\renewcommand{\arraystretch}{1.2}
\noindent 
\begin{tabular}{l l p{7.5cm}} 
\toprule 
\textbf{Data Type} & \textbf{Notation} & \textbf{Description}\\ 
\midrule
integer & $\mathbb{Z}$ & a number without a fractional component in (-$\infty$, $\infty$) \\
natural number & $\mathbb{N}$ & a number without a fractional component in [1, $\infty$) \\
real & $\mathbb{R}$ & any number in (-$\infty$, $\infty$)\\
boolean & \texttt{bool} & Boolean value: either \texttt{True} or \texttt{False} \\
string & \texttt{str} & A sequence of Unicode characters \\
tensor & \texttt{Tensor} & A multi-dimensional array object from PyTorch \\
graph & \texttt{Data} & A graph object from PyTorch Geometric, with node and edge attributes \\
dataset & \texttt{Dataset} & A collection of graph objects for training or evaluation \\
dataloader & \texttt{DataLoader} & A PyTorch Geometric data loader for batching graph data \\
dictionary & \texttt{dict[K $\rightarrow{}$ V]} & A mapping from keys of type \texttt{K} to values of type \texttt{V} \\
list & \texttt{list[T]} & A sequence of elements of type \texttt{T} \\
function & \texttt{Customized Function} & A self-defined callable function\\
\bottomrule
\end{tabular} 
\end{center}

\noindent
Re-ProtGNN uses functions, which
are defined by the data types of their inputs and outputs. Local functions are
described by giving their type signature followed by their specification.

\section{Module Decomposition}

The following table is taken directly from the Module Guide document for this project.

\begin{table}[h!]
\centering
\begin{tabular}{p{0.3\textwidth} p{0.6\textwidth}}
\toprule
\textbf{Level 1} & \textbf{Level 2}\\
\midrule

{Hardware-Hiding} & ~ \\
\midrule

\multirow{4}{0.3\textwidth}{Behaviour-Hiding Module} & Configuration Module \\
& Input Format Module\\
& Control Module\\
& Training Module\\
& Output Visualization Module\\
\midrule

\multirow{3}{0.3\textwidth}{Software Decision Module} & {Model Module}\\
& Inference Module\\
& Explanation Module\\
& Pytorch Module\\
& Pytorch Geometric Module\\
& GUI Module\\
\bottomrule

\end{tabular}
\caption{Module Hierarchy}
\label{TblMH}
\end{table}

\newpage


\section{MIS of Configuration Module} \label{Configurations}

\subsection{Module}
Configuration

\subsection{Uses}
None

\subsection{Syntax}

\subsubsection{Exported Constants}
None

\subsubsection{Exported Access Programs}
None

\subsection{Semantics}

\subsubsection{State Variables}
\begin{itemize}
  \item \texttt{data\_args: DataParser} — Stores dataset-level configuration such as name, directory, splitting strategy, and seed.
  \item \texttt{model\_args: ModelParser} — Stores GNN architecture settings and prototype-related parameters.
  \item \texttt{train\_args: TrainParser} — Stores training hyperparameters including learning rate, batch size, and epoch count.
  \item \texttt{mcts\_args: MCTSParser} — Stores Monte Carlo Tree Search and explanation-specific rollout parameters.
  \item \texttt{random\_seed: int} — Stores the global seed used for generating random numbers.
\end{itemize}

\subsubsection{Environment Variables}
None

\subsubsection{Access Routine Semantics}
None - The state variables in this module are initialized when the system loads and are accessed directly by other modules using:
\begin{quote}
\texttt{from utils.Configures import data\_args, train\_args, model\_args, mcts\_args}
\end{quote}
As such, no explicit accessor routines are exported.

\subsubsection{Local Functions}

\noindent \textbf{DataParser(name: str, dir: str, split: list[\(\mathbb{R}\)], seed: int) \(\rightarrow\) DataParser}
\begin{itemize}
  \item output: Returns a configuration object for dataset settings including \texttt{name}, \texttt{dir}, \texttt{split}, and \texttt{seed}.
\end{itemize}

\noindent \textbf{ModelParser(model\_name: str, hidden\_dim: \(\mathbb{N}\), num\_prototypes: \(\mathbb{N}\)) \(\rightarrow\) ModelParser}
\begin{itemize}
  \item output: Returns a configuration object containing the GNN model name, hidden dimension, and prototype count.
\end{itemize}

\noindent \textbf{TrainParser(batch\_size: \(\mathbb{N}\), lr: \(\mathbb{R}\), epochs: \(\mathbb{N}\)) \(\rightarrow\) TrainParser}
\begin{itemize}
  \item output: Returns a configuration object with the training hyperparameters: \texttt{batch\_size}, \texttt{lr}, and \texttt{epochs}.
\end{itemize}

\noindent \textbf{MCTSParser(num\_rollouts: \(\mathbb{N}\), exploration\_const: \(\mathbb{R}\)) \(\rightarrow\) MCTSParser}
\begin{itemize}
  \item output: Returns a configuration object specifying the number of rollouts and exploration constant for MCTS-based explanation.
\end{itemize}

\vspace{0.5em}






\newpage



\section{MIS of Input Format Module} \label{InputFormat}

\subsection{Module}
dataUtils

\subsection{Uses}
PyTorch Geometric Module (\ref{PyGModule}), PyTorch Module (\ref{TorchModule}), Configuration Module (\ref{Configurations}), Output Visualization Module (\ref{OutputVisualization})

\subsection{Syntax}

\subsubsection{Exported Constants}
None

\subsubsection{Exported Access Programs}
\begin{center}
\begin{tabular}{p{3cm} p{3cm} p{4.3cm} p{4cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
load\_dataset & - & \texttt{tuple[Dataset, int, int, dict[str $\rightarrow$ DataLoader]]} & \texttt{FileNotFoundError}, \texttt{ValueError}, \texttt{NotImplementedError} \\
\hline
\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}
None

\subsubsection{Environment Variables}
\begin{itemize}
  \item \texttt{dataset\_dir: str} — Filesystem path to the dataset root directory, obtained from \texttt{data\_args.dataset\_dir} defined in the Configuration Module.
  \item \texttt{log\_file: str} — Path to the log file used by the \texttt{append\_record()} routine exported from the Output Visualization Module.
\end{itemize}

\subsubsection{Access Routine Semantics}

\noindent \textbf{load\_dataset()}:
\begin{itemize}
  \item transition:
  \begin{itemize}
    \item Loads the dataset using \texttt{data\_args.dataset\_name} and \texttt{data\_args.dataset\_dir}, where \texttt{data\_args} are defined in the Configuration Module.
    \item Logs the dataset name using \texttt{append\_record(data\_args.dataset\_name)}, where \texttt{append\_record()} is a routine exported from the Output Visualization Module
  \end{itemize}
  \item output:
  \begin{itemize}
    \item Returns a tuple: (\texttt{dataset}, \texttt{input\_dim}, \texttt{output\_dim}, \texttt{dataloader}) where:
    \begin{itemize}
      \item \texttt{dataset}: graph dataset object loaded using \texttt{\_get\_dataset()}
      \item \texttt{input\_dim}: number of node features from \texttt{dataset.num\_node\_features}
      \item \texttt{output\_dim}: number of output classes from \texttt{dataset.num\_classes}
      \item \texttt{dataloader}: dictionary of DataLoaders split via \texttt{\_get\_dataloader()}
    \end{itemize}
  \end{itemize}
    \item exception:
    \begin{itemize}
      \item \texttt{FileNotFoundError}: 
      Raised if required dataset files are missing in the specified directory, such as missing raw `.pkl` or `.txt` files for the dataset.
      
      \item \texttt{ValueError}: 
      Raised if raw data files exist but are empty or malformed (e.g., missing node labels).
    
      \item \texttt{NotImplementedError}: 
      Raised if \texttt{data\_args.dataset\_name} does not match any supported dataset (i.e., not MUTAG, BA\_2Motifs, or a MoleculeNet dataset).
    \end{itemize}
\end{itemize}

\subsubsection{Local Functions}

\noindent \textbf{\_get\_dataset(dataset\_dir: str, dataset\_name: str) $\rightarrow$ Dataset}
\begin{itemize}
  \item output: Selects an appropriate dataset loader based on \texttt{dataset\_name} and returns the resulting dataset loaded from \texttt{dataset\_dir}. See the Pytroch Geometric Module~\ref{PyGModule} for the type \texttt{Dataset}.
\end{itemize}

\noindent \textbf{\_get\_dataloader(dataset: Dataset, batch\_size: \(\mathbb{N}\), data\_split\_ratio: list[\(\mathbb{R}\)]) $\rightarrow$ dict[str $\rightarrow$ DataLoader]}
\begin{itemize}
  \item output: Splits the input \texttt{dataset} into train/eval/test sets according to \texttt{data\_split\_ratio}, and returns DataLoaders batched by \texttt{batch\_size}. See the PyTorch Geometric Module~\ref{PyGModule} for the type \texttt{DataLoader}.
\end{itemize}



\newpage










\section{MIS of Control Module} \label{Control}

\subsection{Module}
main

\subsection{Uses}
Configuration Module (\ref{Configurations}), Input Format Module (\ref{InputFormat}), Model Module (\ref{Model}), Training Module (\ref{Train}), Inference Module (\ref{Test}), Explanation Module (\ref{Explanation}), PyTorch Module (\ref{TorchModule})

\subsection{Syntax}

\subsubsection{Exported Constants}
None

\subsubsection{Exported Access Programs}
\begin{center}
\begin{tabular}{p{3cm} p{6cm} p{4.5cm} p{3cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
main & clst: \(\mathbb{R}\), sep: \(\mathbb{R}\) & - & - \\
\hline
\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}
None

\subsubsection{Environment Variables}
\begin{itemize}
  \item \texttt{dataset\_dir: str} — Filesystem path to the dataset root directory (from \texttt{data\_args.dataset\_dir}).
  \item \texttt{checkpoint\_dir: str} — Directory path for saving and loading model checkpoints, constructed using \texttt{data\_args.dataset\_name}.
  \item \texttt{device: str} — Device identifier used by PyTorch for model training and inference (e.g., `cpu' or `cuda').
\end{itemize}

\subsubsection{Access Routine Semantics}

\noindent \textbf{main(clst, sep)}:
\begin{itemize}
  \item transition:
  \begin{itemize}
    \item Loads the dataset and dataloaders using \texttt{load\_dataset()}, which references \texttt{dataset\_dir}.
    \item Initializes a GNN model and loss function using \texttt{setup\_model(input\_dim, output\_dim, model\_args)} from Model Module (\ref{Model}).
    \item Constructs \texttt{checkpoint\_dir := `./src/checkpoint/\{data\_args.dataset\_name\}/'}.
    \item Trains the model using \texttt{train(clst, sep, dataset, dataloader, gnnNets, output\_dim, criterion, checkpoint\_dir)} from Training Module (\ref{Train}).
    \item Loads the best checkpoint from \texttt{checkpoint\_dir}, and updates model weights using \texttt{update\_state\_dict()}.
    \item Evaluates the trained model via \texttt{test(dataloader['test'], gnnNets, criterion)} from Inference Module (\ref{Test}).
    \item Generates explanations using \texttt{exp\_visualize(dataset, dataloader, gnnNets, output\_dim)} from Explanation Module (\ref{Explanation}).
  \end{itemize}
  \item output: None
  \item exception: None
\end{itemize}

\subsubsection{Local Functions}
None




\newpage







\section{MIS of Training Module} \label{Train}

\subsection{Module}
Train

\subsection{Uses}
Configuration Module (\ref{Configurations}), Model Module (\ref{Model}), Explanation Module (\ref{Explanation}), Output Visualization Module (\ref{OutputVisualization}), PyTorch Module (\ref{TorchModule})

\subsection{Syntax}

\subsubsection{Exported Constants}
None

\subsubsection{Exported Access Programs}
\begin{center}
\begin{tabular}{p{2.5cm} p{6.2cm} p{4cm} p{3cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
train & clst: \(\mathbb{R}\), sep: \(\mathbb{R}\), dataset: \texttt{Dataset}, dataloader: \texttt{dict[str $\rightarrow$ DataLoader]}, gnnNets: \texttt{GnnNets}, output\_dim: \(\mathbb{N}\), criterion: \texttt{Customized Function}, ckpt\_dir: \texttt{str} & - & None \\
\hline
\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}
None

\subsubsection{Environment Variables}
\begin{itemize}
  \item \texttt{checkpoint\_dir: str} — Path to the directory for saving model checkpoints.
  \item \texttt{device: str} — Target computation device, used to allocate model weights and prototype vectors.
\end{itemize}

\subsubsection{Access Routine Semantics}

\noindent \textbf{train(clst, sep, dataset, dataloader, gnnNets, output\_dim, criterion, ckpt\_dir)}:
\begin{itemize}
  \item transition:
  \begin{itemize}
    \item Initializes the optimizer using parameters from \texttt{gnnNets} and \texttt{train\_args}.
    \item Logs statistics for \texttt{dataset} using \texttt{\_log\_dataset\_stats(dataset)}.
    \item Iteratively trains the model using batches from \texttt{dataloader['train']} with cluster/separation losses weighted by \texttt{clst} and \texttt{sep}.
    \item Periodically projects prototypes onto embedding space using \texttt{\_project\_prototypes(gnnNets, dataset, ...)}.
    \item Evaluates performance on the validation set using \texttt{\_evaluate(dataloader['eval'], gnnNets, criterion)}.
    \item Saves model checkpoints to \texttt{ckpt\_dir}.
  \end{itemize}
  \item output: None
  \item exception: None
\end{itemize}

\subsubsection{Local Functions}

\noindent \textbf{\_evaluate(eval\_dataloader: DataLoader, model: GnnNets, criterion: Customized Function) \(\rightarrow\) dict[str $\rightarrow$ float]}
\begin{itemize}
  \item transition: None
  \item output: Runs model evaluation on \texttt{eval\_dataloader} and computes loss/accuracy basing on \texttt{criterion}. Returns a dictionary with keys \texttt{`loss'} and \texttt{`acc'}.
\end{itemize}

\noindent \textbf{\_log\_dataset\_stats(dataset: Dataset) \(\rightarrow\) None}
\begin{itemize}
  \item transition: Computes average number of nodes and edges from \texttt{dataset}, and prints the result.
  \item output: None
\end{itemize}

\noindent \textbf{\_project\_prototypes(model: GnnNets, dataset: Dataset, indices: list[\(\mathbb{N}\)], output\_dim: \(\mathbb{N}\)) \(\rightarrow\) None}
\begin{itemize}
  \item transition: Updates each prototype vector in \texttt{model} with a real example from \texttt{dataset} using \texttt{get\_explanation()} from Explanation Module (\ref{Explanation}).
  \item output: None
\end{itemize}





\newpage






\section{MIS of Output Visualization Module} \label{OutputVisualization}

\subsection{Module}
outputUtils

\subsection{Uses}
PyTorch Module (\ref{TorchModule}), PyTorch Geometric Module (\ref{PyGModule}), GUI Module (\ref{MatplotlibGUI})

\subsection{Syntax}

\subsubsection{Exported Constants}
None

\subsubsection{Exported Access Programs}
\begin{center}
\begin{tabular}{p{3.2cm} p{6cm} p{3.5cm} p{3.3cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
ExpPlot & dataset\_name: \texttt{str} & \texttt{ExpPlot instance} & - \\
draw & graph: \texttt{networkx.Graph}, nodelist: \texttt{list[int]}, figname: \texttt{str}, kwargs: \texttt{dict} & - & \texttt{NotImplementedError} \\
append\_record & info: \texttt{str} & - & \texttt{FileNotFoundError} \\
save\_best & ckpt\_dir: \texttt{str}, epoch: \(\mathbb{N}\), gnnNets: \texttt{GnnNets}, model\_name: \texttt{str}, eval\_acc: \(\mathbb{R}\), is\_best: \texttt{bool} & - & - \\
\hline
\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}
None

\subsubsection{Environment Variables}
\begin{itemize}
  \item \texttt{log\_file: str} — Hardcoded path to the log file: \texttt{./results/log/hyper\_search}.
  \item \texttt{device: str} — Computation device (e.g., `cuda' or`cpu') used to store model after saving.
\end{itemize}

\subsubsection{Access Routine Semantics}

\noindent \textbf{ExpPlot(dataset\_name)}:
\begin{itemize}
  \item transition: None
  \item output: Constructs an instance for drawing explanations for \texttt{dataset\_name}. Returns an \texttt{ExpPlot} object.
  \item Note: Please see in PyTorch Geometric Module (\ref{PyGModule}) for the type \texttt{networkx.Graph}.
\end{itemize}

\noindent \textbf{draw(graph, nodelist, figname, kwargs)}:
\begin{itemize}
  \item transition: Calls the drawing routine and uses GUI Module (\ref{MatplotlibGUI}) to generate and save a figure to \texttt{figname}.
  \item output: None
  \item exception: \texttt{NotImplementedError} if \texttt{dataset\_name} is unsupported.
\end{itemize}

\noindent \textbf{append\_record(info)}:
\begin{itemize}
  \item transition: Writes \texttt{info} as a new line to the file located at \texttt{log\_file}.
  \item output: None
  \item exception: \texttt{FileNotFoundError} if the parent directory of \texttt{log\_file} does not exist.
\end{itemize}

\noindent \textbf{save\_best(ckpt\_dir, epoch, gnnNets, model\_name, eval\_acc, is\_best)}:
\begin{itemize}
  \item transition:
  \begin{itemize}
    \item Saves model weights and training metadata to \texttt{ckpt\_dir}.
    \item If \texttt{is\_best=True}, copies this file to \texttt{ckpt\_dir}.
    \item Moves model between \texttt{`cpu'} and \texttt{device := model\_args.device}.
  \end{itemize}
  \item output: None
  \item exception: None
\end{itemize}

\subsubsection{Local Functions}
None




\newpage




\section{MIS of Model Module} \label{Model}

\subsection{Module}
GnnNets

\subsection{Uses}
PyTorch Module (\ref{TorchModule}), Output Visualization Module (\ref{OutputVisualization})

\subsection{Syntax}

\subsubsection{Exported Constants}
None

\subsubsection{Exported Access Programs}
\begin{center}
\begin{tabular}{p{3.2cm} p{6cm} p{4cm} p{3cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
setup\_model & input\_dim: \(\mathbb{N}\), output\_dim: \(\mathbb{N}\), model\_args: \texttt{dict} & tuple[\texttt{GnnNets}, \texttt{Customized Function}] & - \\
\hline
\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}
None

\subsubsection{Environment Variables}
\begin{itemize}
  \item \texttt{device: str} — Target device (e.g., `cuda' or `cpu'), used to move the model after initialization.
  \item \texttt{log\_file: str} — Path to the log file used in \texttt{append\_record()}.
\end{itemize}

\subsubsection{Access Routine Semantics}

\noindent \textbf{setup\_model(input\_dim, output\_dim, model\_args)}:
\begin{itemize}
  \item transition: Instantiates a GNN model with specified \texttt{input\_dim}, \texttt{output\_dim}, and \texttt{model\_args}. Moves the model to \texttt{device}. Writes the model name to \texttt{log\_file} using \texttt{append\_record()}.
  \item output: A tuple containing:
  \begin{itemize}
    \item \texttt{gnnNets}: a model instance supporting GNN forward/inference
    \item \texttt{criterion}: a cross-entropy loss function
  \end{itemize}
  \item exception: None
\end{itemize}

\subsubsection{Local Functions}
None





\newpage








\section{MIS of Inference Module} \label{Test}

\subsection{Module}
evaluation.inference

\subsection{Uses}
Model Module (\ref{Model}), Output Visualization Module (\ref{OutputVisualization}), PyTorch Module (\ref{TorchModule})

\subsection{Syntax}

\subsubsection{Exported Constants}
None

\subsubsection{Exported Access Programs}
\begin{center}
\begin{tabular}{p{3cm} p{6cm} p{5cm} p{2.5cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
run\_inference & test\_dataloader: \texttt{DataLoader}, model: \texttt{GnnNets}, criterion: \texttt{Customized Function} & tuple[dict[str $\rightarrow$ \(\mathbb{R}\)], \(\mathbb{R}^{n \times c}\), \(\mathbb{N}^n\)] & None \\
\hline
\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}
None

\subsubsection{Environment Variables}
\begin{itemize}
  \item \texttt{log\_file: str} — Path to the log file where final test performance is recorded via \texttt{append\_record()}.
\end{itemize}

\subsubsection{Access Routine Semantics}

\noindent \textbf{run\_inference(test\_dataloader, model, criterion)}:
\begin{itemize}
  \item transition:
  \begin{itemize}
    \item Appends the final test loss and accuracy to the \texttt{log\_file} using \texttt{append\_record()}.
  \end{itemize}
  \item output:
  \begin{itemize}
    \item Returns a tuple \texttt{(test\_state, all\_probs, all\_preds)}:
    \begin{itemize}
      \item \texttt{test\_state}: \texttt{dict[str $\rightarrow$ \(\mathbb{R}\)]} containing keys \texttt{`loss'} and \texttt{`acc'}.
      \item \texttt{all\_probs}: \(\mathbb{R}^{n \times c}\) — class probability matrix for \(n\) test samples and \(c\) classes, obtained by passing the data in \texttt{test\_dataloader} into \texttt{model}.
      \item \texttt{all\_preds}: \(\mathbb{N}^n\) — vector of predicted class labels.
    \end{itemize}
  \end{itemize}
  \item exception: None
\end{itemize}

\subsubsection{Local Functions}
None





\newpage




\section{MIS of Explanation Module} \label{Explanation}

\subsection{Module}
Explanation

\subsection{Uses}
Configuration Module (\ref{Configurations}), Output Visualization Module (\ref{Model}), PyTorch Geometric Module (\ref{PyGModule}), PyTorch Module (\ref{TorchModule})

\subsection{Syntax}

\subsubsection{Exported Constants}
None

\subsubsection{Exported Access Programs}

\begin{center}
\begin{tabular}{p{3cm} p{5cm} p{5cm} p{2.5cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
get\_explanation & data: \texttt{Data}, gnnNet: \texttt{GnnNets}, prototype: \(\mathbb{R}^d\) & tuple[list[\(\mathbb{N}\)], \(\mathbb{R}\), \(\mathbb{R}^{d}\)] & None \\
exp\_visualize & dataset: \texttt{Dataset}, dataloader: \texttt{dict[str \(\rightarrow\) DataLoader]}, gnnNets: \texttt{GnnNets}, output\_dim: \(\mathbb{N}\) & - & \texttt{FileNotFoundError} \\
\hline
\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}
None

\subsubsection{Environment Variables}
\begin{itemize}
  \item \texttt{save\_dir: str} — Filesystem path for saving explanation plot images.
\end{itemize}

\subsubsection{Access Routine Semantics}

\noindent \textbf{get\_explanation(data, gnnNet, prototype)}:
\begin{itemize}
  \item transition: None
  \item output:
  \begin{itemize}
    \item Uses \texttt{data}, \texttt{gnnNet}, and \texttt{prototype} to invoke a Monte Carlo Tree Search (MCTS) via the local function \texttt{\_mcts()}.
    \item MCTS explores subgraph coalitions within the graph structure of \texttt{data} and evaluates their similarity to the provided \texttt{prototype} using \texttt{\_prot\_similarity\_scores()}.
    \item Returns:
    \begin{itemize}
      \item \texttt{coalition}: list of node indices selected as the best explanation subgraph.
      \item \texttt{P}: similarity score (\(\in \mathbb{R}\)) between the selected subgraph and the \texttt{prototype}.
      \item \texttt{embedding}: a masked subgraph embedding \(\in \mathbb{R}^{1 \times d}\) extracted by applying \texttt{gnnNet} to the subgraph induced by \texttt{coalition}.
    \end{itemize}
  \end{itemize}
  \item exception: None
\end{itemize}

\noindent \textbf{exp\_visualize(dataset, dataloader, gnnNets, output\_dim)}:
\begin{itemize}
  \item transition:
  \begin{itemize}
    \item Computes $K := \texttt{output\_dim} \times \texttt{model\_args.num\_prototypes\_per\_class}$ random prototype vectors of dimension $d$, fixed for visualization.
    \item Samples 16 graphs from \texttt{dataloader[`train']}.
    \item For each selected graph and for each of the first 10 prototype vectors, calls \texttt{get\_explanation(data, gnnNets, prototype)} to compute explanations.
    \item Saves the explanations to image files in the environment variable \texttt{save\_dir}.
    \item Sets \texttt{save\_dir := `./results/plots/<dataset>\_<model>\_'} using values from \texttt{data\_args.dataset\_name} and \texttt{model\_args.model\_name}, imported from Configuration Module (\ref{Configurations}).
  \end{itemize}
  \item output: None
  \item exception:
  \begin{itemize}
    \item \texttt{FileNotFoundError}: if \texttt{save\_dir} cannot be created due to missing parent directories, invalid paths, or insufficient filesystem permissions.
  \end{itemize}
\end{itemize}


\subsubsection{Local Functions}

\noindent \textbf{\_mcts(data: \texttt{Data}, gnnNet: \texttt{GnnNets}, prototype: \(\mathbb{R}^d\)) \(\rightarrow\) tuple[list[\(\mathbb{N}\)], \(\mathbb{R}\), \(\mathbb{R}^d\)]}
\begin{itemize}
  \item output: Applies a multi-step rollout procedure to search for the optimal node coalition in \texttt{data}, maximizing similarity to the reference vector \texttt{prototype} \(\in \mathbb{R}^d\). Returns the selected node indices, similarity score, and final embedding.
\end{itemize}

\noindent \textbf{\_prot\_similarity\_scores(coalition: list[\(\mathbb{N}\)], data: \texttt{Data}, gnnNet: \texttt{GnnNets}, prototype: \(\mathbb{R}^d\)) \(\rightarrow \mathbb{R}\)}
\begin{itemize}
  \item output: Computes a scalar similarity score \(\in \mathbb{R}\) between the subgraph embedding of nodes in \texttt{coalition} (produced by \texttt{gnnNet}) and the given reference vector \texttt{prototype} \(\in \mathbb{R}^d\), based on squared Euclidean distance.
\end{itemize}



\newpage



\section{MIS of PyTorch Module} \label{TorchModule}

\subsection{Module}
Torch

\subsection{Uses}
None

\subsection{Syntax}

\subsubsection{Exported Constants}
None

\subsubsection{Exported Access Programs}

\begin{center}
\begin{tabular}{p{3.2cm} p{5.5cm} p{4cm} p{2.5cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
Tensor & shape: \texttt{list[int]}, dtype: \texttt{str} & \texttt{Tensor} & - \\
cross\_entropy & logits: \texttt{Tensor}, labels: \texttt{Tensor} & \texttt{Tensor} & - \\
Adam & parameters: \texttt{iterable}, lr: \(\mathbb{R}\) & \texttt{Optimizer} & - \\
\hline
\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}
None

\subsubsection{Environment Variables}
None

\subsubsection{Assumptions}
None

\subsubsection{Access Routine Semantics}

\textbf{Tensor(shape, dtype)}:
\begin{itemize}
  \item output: Returns a tensor initialized with zeros of the given \texttt{shape} and \texttt{dtype}.
\end{itemize}

\textbf{cross\_entropy(logits, labels)}:
\begin{itemize}
  \item output: Computes the cross-entropy loss between \texttt{logits} and \texttt{labels}.
\end{itemize}

\textbf{Adam(parameters, lr)}:
\begin{itemize}
  \item output: Returns an Adam optimizer configured with the given \texttt{parameters} and learning rate \texttt{lr}.
\end{itemize}

\subsubsection{Local Functions}
None



\section{MIS of PyTorch Geometric Module} \label{PyGModule}

\subsection{Module}
PyG

\subsection{Uses}
Torch

\subsection{Syntax}

\subsubsection{Exported Constants}
None

\subsubsection{Exported Access Programs}

\begin{center}
\begin{tabular}{p{3.2cm} p{5.5cm} p{4cm} p{2.5cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
Data & x: \texttt{Tensor}, edge\_index: \texttt{Tensor} & \texttt{Data} & - \\
MoleculeNet & root: \texttt{str}, name: \texttt{str} & \texttt{Dataset} & \texttt{FileNotFoundError} \\
DataLoader & dataset: \texttt{Dataset}, batch\_size: \(\mathbb{N}\) & \texttt{DataLoader} & - \\
to\_networkx & data: \texttt{Data} & \texttt{networkx.Graph} & - \\
\hline
\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}
None

\subsubsection{Environment Variables}
None

\subsubsection{Assumptions}
None

\subsubsection{Access Routine Semantics}

\textbf{Data(x, edge\_index)}:
\begin{itemize}
  \item output: Constructs and returns a PyG graph object using \texttt{x} as node features and \texttt{edge\_index} as edge indices.
\end{itemize}

\textbf{MoleculeNet(root, name)}:
\begin{itemize}
  \item output: Loads the dataset specified by \texttt{name} from directory \texttt{root} and returns a \texttt{Dataset} object.
  \item exception: \texttt{FileNotFoundError} if \texttt{root} does not exist.
\end{itemize}

\textbf{DataLoader(dataset, batch\_size)}:
\begin{itemize}
  \item output: Returns a \texttt{DataLoader} that batches data from the given \texttt{dataset} with batch size \texttt{batch\_size}.
\end{itemize}

\textbf{to\_networkx(data)}:
\begin{itemize}
  \item output: Converts the input PyG \texttt{data} object into a NetworkX graph.
\end{itemize}

\subsubsection{Local Functions}
None


\section{MIS of GUI Module} \label{MatplotlibGUI}

\subsection{Module}
Matplotlib

\subsection{Uses}
None

\subsection{Syntax}

\subsubsection{Exported Constants}
None

\subsubsection{Exported Access Programs}

\begin{center}
\begin{tabular}{p{3.2cm} p{5.5cm} p{4cm} p{2.5cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
axis & axis\_choice: \texttt{str} & - & - \\
title & title\_sentence: \texttt{str} & - & - \\
save\_fig & figname: \texttt{str} & - & \texttt{FileNotFoundError} \\
close & choice: \texttt{str} & - & - \\
\hline
\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}
None

\subsubsection{Environment Variables}
\begin{itemize}
  \item \texttt{figure\_path: str} — Path where the current figure will be saved.
  \item \texttt{axis\_visible: bool} — Whether axes are displayed in the active figure.
  \item \texttt{figure\_title: str} — Title of the current figure.
  \item \texttt{figure\_open: bool} — Whether there are any open figures.
\end{itemize}

\subsubsection{Assumptions}
None.

\subsubsection{Access Routine Semantics}

\noindent \textbf{axis(axis\_choice)}:
\begin{itemize}
  \item transition: If \texttt{axis\_choice == 'off'}, sets \texttt{axis\_visible := False} and disables axes using \texttt{plt.axis('off')}. Otherwise sets \texttt{axis\_visible := True}.
\end{itemize}

\noindent \textbf{title(title\_sentence)}:
\begin{itemize}
  \item transition: Sets \texttt{figure\_title := title\_sentence} and updates the title of the current figure using \texttt{plt.title()}.
\end{itemize}

\noindent \textbf{save\_fig(figname)}:
\begin{itemize}
  \item transition: Sets \texttt{figure\_path := figname} and saves the current figure to the specified path using \texttt{plt.savefig(figname)}.
  \item exception: \texttt{FileNotFoundError} if \texttt{figname} refers to a non-existent directory.
\end{itemize}

\noindent \textbf{close(choice)}:
\begin{itemize}
  \item transition: Closes all active figure windows using \texttt{plt.close(choice)} and sets \texttt{figure\_open := False}.
\end{itemize}


\subsubsection{Local Functions}
None
















  

\newpage

\bibliographystyle {plainnat}
\bibliography {../../../refs/References}
%\bibliography{refs/References}

%\newpage

%\section{Appendix} \label{Appendix}

%\wss{Extra information if required}

%\newpage{}

%\section*{Appendix --- Reflection}

%\wss{Not required for CAS 741 projects}

%The information in this section will be used to evaluate the team members on the
%graduate attribute of Problem Analysis and Design.

%\input{../../Reflection.tex}

%\begin{enumerate}
%  \item What went well while writing this deliverable? 
%  \item What pain points did you experience during this deliverable, and how
%    did you resolve them?
%  \item Which of your design decisions stemmed from speaking to your client(s)
%  or a proxy (e.g. your peers, stakeholders, potential users)? For those that
%  were not, why, and where did they come from?
%  \item While creating the design doc, what parts of your other documents (e.g.
%  requirements, hazard analysis, etc), it any, needed to be changed, and why?
%  \item What are the limitations of your solution?  Put another way, given
%  unlimited resources, what could you do to make the project better? (LO\_ProbSolutions)
%  \item Give a brief overview of other design solutions you considered.  What
%  are the benefits and tradeoffs of those other designs compared with the chosen
%  design?  From all the potential options, why did you select the documented design?
%  (LO\_Explores)
%\end{enumerate}


\end{document}

\documentclass[12pt, titlepage]{article}

\usepackage{amsmath, mathtools}

\usepackage[round]{natbib}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{colortbl}
\usepackage{xr}
\usepackage{hyperref}
\usepackage{longtable}
\usepackage{xfrac}
\usepackage{tabularx}
\usepackage{float}
\usepackage{siunitx}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage[section]{placeins}
\usepackage{caption}
\usepackage{fullpage}

\hypersetup{
bookmarks=true,     % show bookmarks bar?
colorlinks=true,       % false: boxed links; true: colored links
linkcolor=red,          % color of internal links (change box color with linkbordercolor)
citecolor=blue,      % color of links to bibliography
filecolor=magenta,  % color of file links
urlcolor=cyan          % color of external links
}

\usepackage{array}

\externaldocument{../../SRS/SRS}

\input{../../Comments}
\input{../../Common}

\begin{document}

\title{Module Interface Specification for Re-ProtGNN}

\author{\authname}

\date{\today}

\maketitle

\pagenumbering{roman}

\section{Revision History}

\begin{tabularx}{\textwidth}{p{3cm}p{2cm}X}
\toprule {\bf Date} & {\bf Version} & {\bf Notes}\\
\midrule
Mar 19, 2025 & 1.0 & Initial Draft\\
\bottomrule
\end{tabularx}

~\newpage

\section{Symbols, Abbreviations and Acronyms}

See SRS Documentation at \url{https://github.com/Yuanqi-X/Re-ProtGNN/blob/main/docs/SRS/SRS.pdf}.

\newpage

\tableofcontents

\newpage

\pagenumbering{arabic}

\section{Introduction}

The following document details the Module Interface Specifications for Re-ProtGNN, a re-implementation of an interpretable Graph Neural Network (GNN) Framework.

Complementary documents include the System Requirement Specifications
and Module Guide.  The full documentation and implementation can be
found at \url{https://github.com/Yuanqi-X/Re-ProtGNN/tree/main}.

\section{Notation}

The structure of the MIS for modules comes from \citet{HoffmanAndStrooper1995},
with the addition that template modules have been adapted from
\cite{GhezziEtAl2003}.  The mathematical notation comes from Chapter 3 of
\citet{HoffmanAndStrooper1995}.  For instance, the symbol := is used for a
multiple assignment statement and conditional rules follow the form $(c_1
\Rightarrow r_1 | c_2 \Rightarrow r_2 | ... | c_n \Rightarrow r_n )$.

The following table summarizes the primitive data types used by Re-ProtGNN. 

\begin{center}
\renewcommand{\arraystretch}{1.2}
\noindent 
\begin{tabular}{l l p{7.5cm}} 
\toprule 
\textbf{Data Type} & \textbf{Notation} & \textbf{Description}\\ 
\midrule
integer & $\mathbb{Z}$ & a number without a fractional component in (-$\infty$, $\infty$) \\
natural number & $\mathbb{N}$ & a number without a fractional component in [1, $\infty$) \\
real & $\mathbb{R}$ & any number in (-$\infty$, $\infty$)\\
boolean & \texttt{bool} & Boolean value: either \texttt{True} or \texttt{False} \\
string & \texttt{str} & A sequence of Unicode characters \\
tensor & \texttt{Tensor} & A multi-dimensional array object from PyTorch \\
graph & \texttt{Data} & A graph object from PyTorch Geometric, with node and edge attributes \\
dataset & \texttt{Dataset} & A collection of graph objects for training or evaluation \\
dataloader & \texttt{DataLoader} & A PyTorch Geometric data loader for batching graph data \\
dictionary & \texttt{dict[K $\rightarrow{}$ V]} & A mapping from keys of type \texttt{K} to values of type \texttt{V} \\
list & \texttt{list[T]} & A sequence of elements of type \texttt{T} \\
function & \texttt{Customized Function} & A self-defined callable function\\
\bottomrule
\end{tabular} 
\end{center}

\noindent
Re-ProtGNN uses functions, which
are defined by the data types of their inputs and outputs. Local functions are
described by giving their type signature followed by their specification.

\section{Module Decomposition}

The following table is taken directly from the Module Guide document for this project.

\begin{table}[h!]
\centering
\begin{tabular}{p{0.3\textwidth} p{0.6\textwidth}}
\toprule
\textbf{Level 1} & \textbf{Level 2}\\
\midrule

{Hardware-Hiding} & ~ \\
\midrule

\multirow{4}{0.3\textwidth}{Behaviour-Hiding Module} & Configuration Module \\
& Input Format Module\\
& Control Module\\
& Training Module\\
& Output Visualization Module\\
\midrule

\multirow{3}{0.3\textwidth}{Software Decision Module} & {Model Module}\\
& Inference Module\\
& Explanation Module\\
& Pytorch Module\\
& Pytorch Geometric Module\\
& GUI Module\\
\bottomrule

\end{tabular}
\caption{Module Hierarchy}
\label{TblMH}
\end{table}

\newpage


\section{MIS of Configuration Module} \label{Configurations}

\subsection{Module}
Configuration

\subsection{Uses}
None

\subsection{Syntax}

\subsubsection{Exported Constants}
None

\subsubsection{Exported Access Programs}
None

\subsection{Semantics}

\subsubsection{State Variables}
\begin{itemize}
  \item \texttt{data\_args: DataParser} — Stores dataset-level configuration such as name, directory, splitting strategy, and seed.
  \item \texttt{model\_args: ModelParser} — Stores GNN architecture settings and prototype-related parameters.
  \item \texttt{train\_args: TrainParser} — Stores training hyperparameters including learning rate, batch size, and epoch count.
  \item \texttt{mcts\_args: MCTSParser} — Stores Monte Carlo Tree Search and explanation-specific rollout parameters.
  \item \texttt{random\_seed: int} — Stores the global seed used for generating random numbers.
\end{itemize}

\subsubsection{Environment Variables}
None

\subsubsection{Access Routine Semantics}
None - The state variables in this module are initialized when the system loads and are accessed directly by other modules using:
\begin{quote}
\texttt{from utils.Configures import data\_args, train\_args, model\_args, mcts\_args}
\end{quote}
As such, no explicit accessor routines are exported.

\subsubsection{Local Functions}

\noindent \textbf{DataParser(name: str, dir: str, split: list[\(\mathbb{R}\)], seed: int) \(\rightarrow\) DataParser}
\begin{itemize}
  \item output: Returns a configuration object for dataset settings including \texttt{name}, \texttt{dir}, \texttt{split}, and \texttt{seed}.
\end{itemize}

\noindent \textbf{ModelParser(model\_name: str, hidden\_dim: \(\mathbb{N}\), num\_prototypes: \(\mathbb{N}\)) \(\rightarrow\) ModelParser}
\begin{itemize}
  \item output: Returns a configuration object containing the GNN model name, hidden dimension, and prototype count.
\end{itemize}

\noindent \textbf{TrainParser(batch\_size: \(\mathbb{N}\), lr: \(\mathbb{R}\), epochs: \(\mathbb{N}\)) \(\rightarrow\) TrainParser}
\begin{itemize}
  \item output: Returns a configuration object with the training hyperparameters: \texttt{batch\_size}, \texttt{lr}, and \texttt{epochs}.
\end{itemize}

\noindent \textbf{MCTSParser(num\_rollouts: \(\mathbb{N}\), exploration\_const: \(\mathbb{R}\)) \(\rightarrow\) MCTSParser}
\begin{itemize}
  \item output: Returns a configuration object specifying the number of rollouts and exploration constant for MCTS-based explanation.
\end{itemize}

\vspace{0.5em}






\newpage



\section{MIS of Input Format Module} \label{InputFormat}

\subsection{Module}
dataUtils

\subsection{Uses}
PyTorch Geometric Module (\ref{PyGModule}), PyTorch Module (\ref{TorchModule}), Configuration Module (\ref{Configurations}), Output Visualization Module (\ref{OutputVisualization})

\subsection{Syntax}

\subsubsection{Exported Constants}
None

\subsubsection{Exported Access Programs}
\begin{center}
\begin{tabular}{p{3cm} p{3cm} p{4.3cm} p{4cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
load\_dataset & - & \texttt{tuple[Dataset, int, int, dict[str $\rightarrow$ DataLoader]]} & \texttt{FileNotFoundError}, \texttt{ValueError}, \texttt{NotImplementedError} \\
\hline
\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}
None

\subsubsection{Environment Variables}
\begin{itemize}
  \item \texttt{dataset\_dir: str} — Filesystem path to the dataset root directory, obtained from \texttt{data\_args.dataset\_dir} defined in the Configuration Module.
  \item \texttt{log\_file: str} — Path to the log file used by the \texttt{append\_record()} routine exported from the Output Visualization Module.
\end{itemize}

\subsubsection{Access Routine Semantics}

\noindent \textbf{load\_dataset()}:
\begin{itemize}
  \item transition:
  \begin{itemize}
    \item Loads the dataset using \texttt{data\_args.dataset\_name} and \texttt{data\_args.dataset\_dir}, where \texttt{data\_args} are defined in the Configuration Module.
    \item Logs the dataset name using \texttt{append\_record(data\_args.dataset\_name)}, where \texttt{append\_record()} is a routine exported from the Output Visualization Module
  \end{itemize}
  \item output:
  \begin{itemize}
    \item Returns a tuple: (\texttt{dataset}, \texttt{input\_dim}, \texttt{output\_dim}, \texttt{dataloader}) where:
    \begin{itemize}
      \item \texttt{dataset}: graph dataset object loaded using \texttt{\_get\_dataset()}
      \item \texttt{input\_dim}: number of node features from \texttt{dataset.num\_node\_features}
      \item \texttt{output\_dim}: number of output classes from \texttt{dataset.num\_classes}
      \item \texttt{dataloader}: dictionary of DataLoaders split via \texttt{\_get\_dataloader()}
    \end{itemize}
  \end{itemize}
    \item exception:
    \begin{itemize}
      \item \texttt{FileNotFoundError}: 
      Raised if required dataset files are missing in the specified directory, such as missing raw `.pkl` or `.txt` files for the dataset.
      
      \item \texttt{ValueError}: 
      Raised if raw data files exist but are empty or malformed (e.g., missing node labels).
    
      \item \texttt{NotImplementedError}: 
      Raised if \texttt{data\_args.dataset\_name} does not match any supported dataset (i.e., not MUTAG, BA\_2Motifs, or a MoleculeNet dataset).
    \end{itemize}
\end{itemize}

\subsubsection{Local Functions}

\noindent \textbf{\_get\_dataset(dataset\_dir: str, dataset\_name: str) $\rightarrow$ Dataset}
\begin{itemize}
  \item output: Selects an appropriate dataset loader based on \texttt{dataset\_name} and returns the resulting dataset loaded from \texttt{dataset\_dir}. See the Pytroch Geometric Module~\ref{PyGModule} for the type \texttt{Dataset}.
\end{itemize}

\noindent \textbf{\_get\_dataloader(dataset: Dataset, batch\_size: \(\mathbb{N}\), data\_split\_ratio: list[\(\mathbb{R}\)]) $\rightarrow$ dict[str $\rightarrow$ DataLoader]}
\begin{itemize}
  \item output: Splits the input \texttt{dataset} into train/eval/test sets according to \texttt{data\_split\_ratio}, and returns DataLoaders batched by \texttt{batch\_size}. See the PyTorch Geometric Module~\ref{PyGModule} for the type \texttt{DataLoader}.
\end{itemize}



\newpage










\section{MIS of Control Module} \label{Control}

\subsection{Module}
main

\subsection{Uses}
Configuration Module (\ref{Configurations}), Input Format Module (\ref{InputFormat}), Model Module (\ref{Model}), Training Module (\ref{Train}), Inference Module (\ref{Test}), Explanation Module (\ref{Explanation}), PyTorch Module (\ref{TorchModule})

\subsection{Syntax}

\subsubsection{Exported Constants}
None

\subsubsection{Exported Access Programs}
\begin{center}
\begin{tabular}{p{3cm} p{6cm} p{4.5cm} p{3cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
main & clst: \(\mathbb{R}\), sep: \(\mathbb{R}\) & - & - \\
\hline
\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}
None

\subsubsection{Environment Variables}
\begin{itemize}
  \item \texttt{dataset\_dir: str} — Filesystem path to the dataset root directory (from \texttt{data\_args.dataset\_dir}).
  \item \texttt{checkpoint\_dir: str} — Directory path for saving and loading model checkpoints, constructed using \texttt{data\_args.dataset\_name}.
  \item \texttt{device: str} — Device identifier used by PyTorch for model training and inference (e.g., `cpu' or `cuda').
\end{itemize}

\subsubsection{Access Routine Semantics}

\noindent \textbf{main(clst, sep)}:
\begin{itemize}
  \item transition:
  \begin{itemize}
    \item Loads the dataset and dataloaders using \texttt{load\_dataset()}, which references \texttt{dataset\_dir}.
    \item Initializes a GNN model and loss function using \texttt{setup\_model(input\_dim, output\_dim, model\_args)} from Model Module (\ref{Model}).
    \item Constructs \texttt{checkpoint\_dir := "./src/checkpoint/\{data\_args.dataset\_name\}/"}.
    \item Trains the model using \texttt{train(clst, sep, dataset, dataloader, gnnNets, output\_dim, criterion, checkpoint\_dir)} from Training Module (\ref{Train}).
    \item Loads the best checkpoint from \texttt{checkpoint\_dir}, and updates model weights using \texttt{update\_state\_dict()}.
    \item Evaluates the trained model via \texttt{test(dataloader['test'], gnnNets, criterion)} from Inference Module (\ref{Test}).
    \item Generates explanations using \texttt{exp\_visualize(dataset, dataloader, gnnNets, output\_dim)} from Explanation Module (\ref{Explanation}).
  \end{itemize}
  \item output: None
  \item exception: None
\end{itemize}

\subsubsection{Local Functions}
None




\newpage







\section{MIS of Training Module} \label{Train} 

\subsection{Module}
Train

\subsection{Uses}
Hardware-Hiding Module, Configuration Module (\ref{Configurations}), Model Module (\ref{Model}), Explanation Module (\ref{OutputVisualization}), Output Visualization Module (\ref{OutputVisualization})

\subsection{Syntax}

\subsubsection{Exported Constants}
None

\subsubsection{Exported Access Programs}

\begin{center}
\begin{tabular}{p{2cm} p{6cm} p{4cm} p{3.5cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
train & model: \texttt{GnnNets}, dataset: \texttt{Dataset}, dataloader: \texttt{dict[str \(\rightarrow\) DataLoader]}, clst: \(\mathbb{R}\), sep: \(\mathbb{R}\) & - & \texttt{FileNotFoundError} \\
\hline
\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}
None

\subsubsection{Environment Variables}
Filesystem: the file system for saving model checkpoints.

\subsubsection{Assumptions}
None

\subsubsection{Access Routine Semantics}

\noindent train(model, dataset, dataloader, clst, sep):
\begin{itemize}
\item transition: Trains the model using the provided data and hyperparameters. Projects prototypes periodically. Monitors evaluation accuracy, saves the best-performing model to disk.
\item output: None
\item exception:     
    \begin{itemize}
        \item \texttt{FileNotFoundError}: if the dataset path or checkpoint directory is invalid
    \end{itemize}
\end{itemize}

\subsubsection{Local Functions}

\noindent
\textbf{evaluate(loader: \texttt{DataLoader}, model: \texttt{GnnNets}, criterion: \texttt{Customized Function}) \(\rightarrow\) \texttt{dict[str \(\rightarrow\) float]}}
\begin{itemize}
  \item transition: None
  \item output: A dictionary containing the average loss and accuracy over the input dataset split. Specifically:
    \begin{itemize}
      \item \texttt{"loss"}: average loss (float)
      \item \texttt{"acc"}: classification accuracy (float)
    \end{itemize}
  \item exception: None
\end{itemize}






\section{MIS of Output Visualization Module} \label{OutputVisualization}

\subsection{Module}
OutputVisualize

\subsection{Uses}
Hardware-Hiding Module

\subsection{Syntax}

\subsubsection{Exported Constants}
None

\subsubsection{Exported Access Programs}

\begin{center}
\begin{tabular}{p{3cm} p{5cm} p{4.5cm} p{3cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
PlotUtils & dataset\_name: \texttt{str} & \texttt{PlotUtils instance} & - \\
plot & graph: \texttt{Data}, nodelist: \texttt{list[int]}, figname: \texttt{str}, kwargs: \texttt{dict} & - & - \\
append\_record & info: \texttt{str} & - & \texttt{FileNotFoundError} \\
\hline
\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}
None

\subsubsection{Environment Variables}
\begin{itemize}
  \item Filesystem: the file system for saving log files and outputting explanation images.
\end{itemize}

\subsubsection{Assumptions}
None

\subsubsection{Access Routine Semantics}

\noindent \textbf{PlotUtils(dataset\_name)}:
\begin{itemize}
  \item transition: None
  \item output: A \texttt{PlotUtils} object with methods for graph visualization.
  \item exception: None
\end{itemize}


\noindent \textbf{plot(graph, nodelist, figname, kwargs)}:
\begin{itemize}
  \item transition: Generates explanation images and saves them to the specified path.
  \item output: None
  \item exception: None
\end{itemize}


\noindent \textbf{append\_record(info)}:
\begin{itemize}
  \item transition: Appends the \texttt{info} string to the log file located in the given log directory.
  \item output: None
  \item exception: 
  \begin{itemize}
    \item \texttt{FileNotFoundError}: if the directory does not exist.
  \end{itemize}
\end{itemize}



\subsubsection{Local Functions}
None









\section{MIS of Model Module} \label{Model}

\subsection{Module}
GnnNets

\subsection{Uses}
None

\subsection{Syntax}

\subsubsection{Exported Constants}
None

\subsubsection{Exported Access Programs}

\begin{center}
\begin{tabular}{p{3cm} p{4.5cm} p{4.5cm} p{3cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
GnnNets & input\_dim: \texttt{int}, output\_dim: \texttt{int}, model\_args: \texttt{dict} & \texttt{GnnNets} & \texttt{NotImplementedError} \\
forward & data: \texttt{Data}, protgnn\_plus: \texttt{bool}, similarity: \texttt{Tensor} & logits: \texttt{Tensor}, prob: \texttt{Tensor}, emb1: \texttt{Tensor}, emb2: \texttt{Tensor}, min\_distances: \texttt{Tensor} & - \\
update\_state\_dict & state\_dict: \texttt{dict} & - & - \\
to\_device & - & - & - \\

\hline
\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}
\begin{itemize}
  \item \texttt{self.model}: the internal GNN encoder consisting of learnable layers.
  \item \texttt{self.prototype\_vectors}: a tensor containing learnable prototype embeddings, where each prototype represents a latent concept tied to a specific class.
  \item \texttt{self.device}: the computing device (e.g., 'cpu' or 'cuda') on which the model is running.
\end{itemize}

\subsubsection{Environment Variables}
GPU/CPU hardware for model training and inference.

\subsubsection{Assumptions}
None

\subsubsection{Access Routine Semantics}

\noindent \textbf{GnnNets(input\_dim, output\_dim, model\_args)}:
\begin{itemize}
  \item transition: None
  \item output: Returns an instance of the \texttt{GnnNets} class with specified input/output dimensions and model hyperparameters.
  \item exception:     
    \begin{itemize}
      \item \texttt{NotImplementedError}: if the specified model name in \texttt{model\_args} is unsupported.
    \end{itemize}
\end{itemize}

\noindent \textbf{forward(data, protgnn\_plus, similarity)}:
\begin{itemize}
  \item transition: Moves graph data to the correct device and performs a forward pass through the model.
  \item output:
    \begin{itemize}
      \item \texttt{logits}: raw output scores for each class.
      \item \texttt{prob}: predicted class probabilities for each input graph, obtained by applying softmax to logits.
      \item \texttt{emb1}: intermediate representation from an early layer of the model.
      \item \texttt{emb2}: deeper-level embedding capturing higher-level graph features after additional processing layers.
      \item \texttt{min\_distances}: for each input graph, the minimum distance to each prototype vector.
    \end{itemize}
  \item exception: None
\end{itemize}

\noindent \textbf{update\_state\_dict(state\_dict)}:
\begin{itemize}
  \item transition: Loads and updates model parameters from a dictionary of saved weights.
  \item output: None
  \item exception: None
\end{itemize}

\noindent \textbf{to\_device()}:
\begin{itemize}
  \item transition: Moves all model components to the device.
  \item output: None
  \item exception: None
\end{itemize}

\subsubsection{Local Functions}
None





\section{MIS of Inference Module} \label{Test}

\subsection{Module}
Test

\subsection{Uses}
Model Module (\ref{Model}), Output Visualization Module (\ref{OutputVisualization})

\subsection{Syntax}

\subsubsection{Exported Constants}
None

\subsubsection{Exported Access Programs}

\begin{center}
\begin{tabular}{p{2cm} p{6cm} p{4cm} p{3.5cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
test & model: \texttt{GnnNets}, dataloader: \texttt{DataLoader} & - & \texttt{RuntimeError} \\
\hline
\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}
None

\subsubsection{Environment Variables}
None

\subsubsection{Assumptions}
The model has been trained and its best checkpoint has been loaded.

\subsubsection{Access Routine Semantics}

\noindent test(model, dataloader):
\begin{itemize}
\item transition: Evaluates the trained model on the test set. Computes loss and accuracy, and uses the Output Visualization Module to log results.
\item output: None
\item exception:     
    \begin{itemize}
        \item \texttt{RuntimeError}: if inference fails due to an invalid model state or shape mismatch
    \end{itemize}
\end{itemize}

\subsubsection{Local Functions}
None














\section{MIS of Explanation Module} \label{Explanation}

\subsection{Module}
Explanation

\subsection{Uses}
Configuration Module (\ref{Configurations})

\subsection{Syntax}

\subsubsection{Exported Constants}
None

\subsubsection{Exported Access Programs}

\begin{center}
\begin{tabular}{p{3cm} p{5cm} p{4.5cm} p{3cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
get\_explanation & data: \texttt{Data}, gnnNet: \texttt{GnnNets}, prototype: \texttt{Tensor} & coalition: \texttt{list[int]}, P: \(\mathbb{R}\), embedding: \texttt{Tensor} & - \\
\hline
\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}
None

\subsubsection{Environment Variables}
None

\subsubsection{Assumptions}
None

\subsubsection{Access Routine Semantics}

\noindent \textbf{get\_explanation(data, gnnNet, prototype)}:
\begin{itemize}
  \item transition: None
  \item output:
  \begin{itemize}
    \item \texttt{coalition}: list of node indices forming the explanation.
    \item \texttt{P}: float score indicating similarity to the prototype.
    \item \texttt{embedding}: matrix of floats representing the masked subgraph embedding.
  \end{itemize}
  \item exception: None
\end{itemize}

\subsubsection{Local Functions}

\noindent 
\textbf{MCTSNode(coalition: \texttt{list[int]}, data: \texttt{Data}, ori\_graph: \texttt{networkx.Graph}, c\_puct: \(\mathbb{R}\), W: \(\mathbb{R}\), N: \(\mathbb{R}\), P: \(\mathbb{R}\)) \(\rightarrow\) \texttt{MCTSNode}}
\begin{itemize}
  \item transition: None
  \item output: A node object representing a state in the search tree.
  \item exception: None
\end{itemize}

\noindent 
\textbf{mcts\_rollout(tree\_node: \texttt{MCTSNode}, state\_map: \texttt{dict}, data: \texttt{Data}, graph: \texttt{networkx.Graph}, score\_func: \texttt{Customized Function}) \(\rightarrow \mathbb{R}\)}
\begin{itemize}
  \item transition: None
  \item output: Scalar value representing the reward from this rollout.
  \item exception: None
\end{itemize}

\noindent 
\textbf{child\_scores(score\_func: \texttt{Customized Function}, children: \texttt{list[MCTSNode]}) \(\rightarrow\) \texttt{list[\(\mathbb{R}\)]}}
\begin{itemize}
  \item transition: None
  \item output: List of float scores, one for each child.
  \item exception: None
\end{itemize}

\noindent 
\textbf{prot\_score(coalition: \texttt{list[int]}, data: \texttt{Data}, gnnNet: \texttt{GnnNets}, prototype: \texttt{Tensor}) \(\rightarrow \mathbb{R}\)}
\begin{itemize}
  \item transition: None
  \item output: A float similarity score (higher = more aligned with prototype).
  \item exception: None
\end{itemize}




\section{MIS of PyTorch Module} \label{TorchModule}

\subsection{Module}
Torch

\subsection{Uses}
None

\subsection{Syntax}

\subsubsection{Exported Constants}
None

\subsubsection{Exported Access Programs}

\begin{center}
\begin{tabular}{p{3.2cm} p{5.5cm} p{4cm} p{2.5cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
Tensor & shape: \texttt{list[int]}, dtype: \texttt{str} & \texttt{Tensor} & - \\
cross\_entropy & logits: \texttt{Tensor}, labels: \texttt{Tensor} & \texttt{Tensor} & - \\
Adam & parameters: \texttt{iterable}, lr: \(\mathbb{R}\) & \texttt{Optimizer} & - \\
\hline
\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}
None

\subsubsection{Environment Variables}
None

\subsubsection{Assumptions}
None

\subsubsection{Access Routine Semantics}

\textbf{Tensor(shape, dtype)}:
\begin{itemize}
  \item output: Returns a tensor initialized with zeros of the given \texttt{shape} and \texttt{dtype}.
\end{itemize}

\textbf{cross\_entropy(logits, labels)}:
\begin{itemize}
  \item output: Computes the cross-entropy loss between \texttt{logits} and \texttt{labels}.
\end{itemize}

\textbf{Adam(parameters, lr)}:
\begin{itemize}
  \item output: Returns an Adam optimizer configured with the given \texttt{parameters} and learning rate \texttt{lr}.
\end{itemize}

\subsubsection{Local Functions}
None



\section{MIS of PyTorch Geometric Module} \label{PyGModule}

\subsection{Module}
PyG

\subsection{Uses}
Torch

\subsection{Syntax}

\subsubsection{Exported Constants}
None

\subsubsection{Exported Access Programs}

\begin{center}
\begin{tabular}{p{3.2cm} p{5.5cm} p{4cm} p{2.5cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
Data & x: \texttt{Tensor}, edge\_index: \texttt{Tensor} & \texttt{Data} & - \\
MoleculeNet & root: \texttt{str}, name: \texttt{str} & \texttt{Dataset} & \texttt{FileNotFoundError} \\
DataLoader & dataset: \texttt{Dataset}, batch\_size: \(\mathbb{N}\) & \texttt{DataLoader} & - \\
to\_networkx & data: \texttt{Data} & \texttt{networkx.Graph} & - \\
\hline
\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}
None

\subsubsection{Environment Variables}
None

\subsubsection{Assumptions}
None

\subsubsection{Access Routine Semantics}

\textbf{Data(x, edge\_index)}:
\begin{itemize}
  \item output: Constructs and returns a PyG graph object using \texttt{x} as node features and \texttt{edge\_index} as edge indices.
\end{itemize}

\textbf{MoleculeNet(root, name)}:
\begin{itemize}
  \item output: Loads the dataset specified by \texttt{name} from directory \texttt{root} and returns a \texttt{Dataset} object.
  \item exception: \texttt{FileNotFoundError} if \texttt{root} does not exist.
\end{itemize}

\textbf{DataLoader(dataset, batch\_size)}:
\begin{itemize}
  \item output: Returns a \texttt{DataLoader} that batches data from the given \texttt{dataset} with batch size \texttt{batch\_size}.
\end{itemize}

\textbf{to\_networkx(data)}:
\begin{itemize}
  \item output: Converts the input PyG \texttt{data} object into a NetworkX graph.
\end{itemize}

\subsubsection{Local Functions}
None


\section{MIS of GUI Module} \label{MatplotlibGUI}

\subsection{Module}
Matplotlib

\subsection{Uses}
None

\subsection{Syntax}

\subsubsection{Exported Constants}
None

\subsubsection{Exported Access Programs}

\begin{center}
\begin{tabular}{p{3.2cm} p{5.5cm} p{4cm} p{2.5cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
axis & axis\_choice: \texttt{str} & - & - \\
title & title\_sentence: \texttt{str} & - & - \\
save\_fig & figname: \texttt{str} & - & \texttt{FileNotFoundError} \\
close & choice: \texttt{str} & - & - \\
\hline
\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}
None

\subsubsection{Environment Variables}
\begin{itemize}
  \item \texttt{figure\_path: str} — Path where the current figure will be saved.
  \item \texttt{axis\_visible: bool} — Whether axes are displayed in the active figure.
  \item \texttt{figure\_title: str} — Title of the current figure.
  \item \texttt{figure\_open: bool} — Whether there are any open figures.
\end{itemize}

\subsubsection{Assumptions}
None.

\subsubsection{Access Routine Semantics}

\noindent \textbf{axis(axis\_choice)}:
\begin{itemize}
  \item transition: If \texttt{axis\_choice == 'off'}, sets \texttt{axis\_visible := False} and disables axes using \texttt{plt.axis('off')}. Otherwise sets \texttt{axis\_visible := True}.
\end{itemize}

\noindent \textbf{title(title\_sentence)}:
\begin{itemize}
  \item transition: Sets \texttt{figure\_title := title\_sentence} and updates the title of the current figure using \texttt{plt.title()}.
\end{itemize}

\noindent \textbf{save\_fig(figname)}:
\begin{itemize}
  \item transition: Sets \texttt{figure\_path := figname} and saves the current figure to the specified path using \texttt{plt.savefig(figname)}.
  \item exception: \texttt{FileNotFoundError} if \texttt{figname} refers to a non-existent directory.
\end{itemize}

\noindent \textbf{close(choice)}:
\begin{itemize}
  \item transition: Closes all active figure windows using \texttt{plt.close(choice)} and sets \texttt{figure\_open := False}.
\end{itemize}


\subsubsection{Local Functions}
None
















  

\newpage

\bibliographystyle {plainnat}
\bibliography {../../../refs/References}
%\bibliography{refs/References}

%\newpage

%\section{Appendix} \label{Appendix}

%\wss{Extra information if required}

%\newpage{}

%\section*{Appendix --- Reflection}

%\wss{Not required for CAS 741 projects}

%The information in this section will be used to evaluate the team members on the
%graduate attribute of Problem Analysis and Design.

%\input{../../Reflection.tex}

%\begin{enumerate}
%  \item What went well while writing this deliverable? 
%  \item What pain points did you experience during this deliverable, and how
%    did you resolve them?
%  \item Which of your design decisions stemmed from speaking to your client(s)
%  or a proxy (e.g. your peers, stakeholders, potential users)? For those that
%  were not, why, and where did they come from?
%  \item While creating the design doc, what parts of your other documents (e.g.
%  requirements, hazard analysis, etc), it any, needed to be changed, and why?
%  \item What are the limitations of your solution?  Put another way, given
%  unlimited resources, what could you do to make the project better? (LO\_ProbSolutions)
%  \item Give a brief overview of other design solutions you considered.  What
%  are the benefits and tradeoffs of those other designs compared with the chosen
%  design?  From all the potential options, why did you select the documented design?
%  (LO\_Explores)
%\end{enumerate}


\end{document}
